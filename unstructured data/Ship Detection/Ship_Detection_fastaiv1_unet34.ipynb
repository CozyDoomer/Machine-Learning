{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "66f1a6a2a44231a6b8e16478d5bd8cc1dddc5398"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chrun\\Anaconda3\\envs\\fastai\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: cymem.cymem.Pool size changed, may indicate binary incompatibility. Expected 48 from C header, got 64 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\chrun\\Anaconda3\\envs\\fastai\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: cymem.cymem.Address size changed, may indicate binary incompatibility. Expected 24 from C header, got 40 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "\n",
    "from fastprogress import master_bar, progress_bar\n",
    "\n",
    "from matplotlib import patches, patheffects\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.measure import label, regionprops\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "```text\n",
      "=== Software === \n",
      "python version  : 3.6.6\n",
      "fastai version  : 1.0.20\n",
      "torch version   : 0.4.1\n",
      "torch cuda ver  : 9.2\n",
      "torch cuda is   : available\n",
      "torch cudnn ver : 7104\n",
      "torch cudnn is  : enabled\n",
      "\n",
      "=== Hardware === \n",
      "torch available : 1\n",
      "  - gpu0        : GeForce GTX 1080\n",
      "\n",
      "=== Environment === \n",
      "platform        : Windows-10-10.0.17134-SP0\n",
      "conda env       : fastai\n",
      "python          : C:\\Users\\chrun\\Anaconda3\\envs\\fastai\\python.exe\n",
      "sys.path        : \n",
      "C:\\Users\\chrun\\Downloads\\pysc2-examples-master\\pysc2-examples-master\\env2\\atari-py-master2\n",
      "C:\\Users\\chrun\\Anaconda3\\envs\\fastai\\python36.zip\n",
      "C:\\Users\\chrun\\Anaconda3\\envs\\fastai\\DLLs\n",
      "C:\\Users\\chrun\\Anaconda3\\envs\\fastai\\lib\n",
      "C:\\Users\\chrun\\Anaconda3\\envs\\fastai\n",
      "C:\\Users\\chrun\\Anaconda3\\envs\\fastai\\lib\\site-packages\n",
      "C:\\Users\\chrun\\Anaconda3\\envs\\fastai\\lib\\site-packages\\defusedxml-0.5.0-py3.6.egg\n",
      "C:\\Users\\chrun\\Anaconda3\\envs\\fastai\\lib\\site-packages\\win32\n",
      "C:\\Users\\chrun\\Anaconda3\\envs\\fastai\\lib\\site-packages\\win32\\lib\n",
      "C:\\Users\\chrun\\Anaconda3\\envs\\fastai\\lib\\site-packages\\Pythonwin\n",
      "C:\\Users\\chrun\\Anaconda3\\envs\\fastai\\lib\\site-packages\\IPython\\extensions\n",
      "C:\\Users\\chrun\\.ipython\n",
      "no nvidia-smi is found\n",
      "```\n",
      "\n",
      "Please make sure to include opening/closing ``` when you paste into forums/github to make the reports appear formatted as code sections.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_install(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "## Stage 1 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data')\n",
    "TMP_PATH = \"tmp/tmp\"\n",
    "MODEL_PATH = \"tmp/model/\"\n",
    "sz = 128\n",
    "arch = models.resnet34\n",
    "bs = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_masks_fn = f'{PATH}/train_ship_segmentations_v2.csv'\n",
    "train_masks_path = Path(PATH/'train_ship_segmentations_v2.csv')\n",
    "\n",
    "images_path = Path(PATH/'train_v2')\n",
    "\n",
    "masks_path = Path(PATH/'train_masks_sampled')\n",
    "\n",
    "images_test_path = Path(PATH/'test_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00003e153.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001124c7.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000155de5.jpg</td>\n",
       "      <td>264661 17 265429 33 266197 33 266965 33 267733...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>360486 1 361252 4 362019 5 362785 8 363552 10 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>51834 9 52602 9 53370 9 54138 9 54906 9 55674 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId                                      EncodedPixels\n",
       "0  00003e153.jpg                                                NaN\n",
       "1  0001124c7.jpg                                                NaN\n",
       "2  000155de5.jpg  264661 17 265429 33 266197 33 266965 33 267733...\n",
       "3  000194a2d.jpg  360486 1 361252 4 362019 5 362785 8 363552 10 ...\n",
       "4  000194a2d.jpg  51834 9 52602 9 53370 9 54138 9 54906 9 55674 ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks = pd.read_csv(train_masks_fn)\n",
    "masks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image = '000155de5.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 42556 image files with masks\n"
     ]
    }
   ],
   "source": [
    "images_with_ship = masks.ImageId[masks.EncodedPixels.isnull()==False]\n",
    "images_with_ship = np.unique(images_with_ship.values)\n",
    "print('There are ' +str(len(images_with_ship)) + ' image files with masks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Undersampling the empty masks (only needed once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grouped_masks = masks.groupby('ImageId', as_index=False).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(grouped_masks[grouped_masks.EncodedPixels==0]), len(grouped_masks[grouped_masks.EncodedPixels>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "empty_masks = grouped_masks[grouped_masks.EncodedPixels==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "undersampled_masks = empty_masks.ImageId.sample(n=len(grouped_masks[grouped_masks.EncodedPixels>0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample_ids = undersampled_masks.append(grouped_masks[grouped_masks.EncodedPixels>0].ImageId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sampled_masks = masks.set_index('ImageId').loc[sample_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sampled_masks.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(sampled_masks['ImageId'].unique()), len(sampled_masks[sampled_masks.EncodedPixels.isnull()]['ImageId'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sampled_masks.sample(frac=1).reset_index(drop=True).to_csv(PATH/sampled_seg, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''# this is for converting the masks to images\n",
    "#%%time\n",
    "for image_id in sampled_masks.ImageId.unique():\n",
    "    rle_0 = sampled_masks.query(f'ImageId==\"{image_id}\"')['EncodedPixels']\n",
    "    img_0 = masks_as_image(rle_0)\n",
    "    \n",
    "    rle_1 = multi_rle_encode(img_0)\n",
    "    img_1 = masks_as_image(rle_1)\n",
    "    \n",
    "    cv2.imwrite(f'data/train_masks_sampled/mask_{image_id}', img_1[:, :, 0]*255)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When undersampling is done create datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_images = [w[5:] for w in os.listdir(masks_path)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_names = np.array([Path(images_path/f'{image_id}') for image_id in sampled_images])[:100]\n",
    "y_names = np.array([Path(masks_path/f'{mask_id}') for mask_id in os.listdir(masks_path)])[:100]\n",
    "x_test_names = np.array([Path(images_test_path/f'{image_id}') for image_id in os.listdir(images_test_path)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(val_pct):\n",
    "    val_idxs = range(int(len(x_names) * val_pct))\n",
    "    val = [o  not in val_idxs for o in range(len(x_names))]\n",
    "    arrs = arrays_split(val, x_names, y_names)\n",
    "    return [SegmentationDataset(*o, classes=['Boat']) for o in arrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds,valid_ds = get_datasets(val_pct=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = SegmentationDataset(x_test_names,x_test_names, classes=['Boat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 768, 768]),\n",
       " torch.Size([1, 768, 768]),\n",
       " fastai.vision.image.Image,\n",
       " fastai.vision.image.ImageSegment)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = next(iter(train_ds))\n",
    "x.shape, y.shape, type(x), type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfm_datasets(sz=128, val_pct=0.2):\n",
    "    datasets = get_datasets(val_pct=0.2)\n",
    "    tfms = get_transforms(do_flip=True, max_rotate=10, max_lighting=0.2)\n",
    "    return transform_datasets(train_ds, valid_ds, test_ds=test_ds, tfms=tfms, tfm_y=True, size=sz, padding_mode='border')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tds, _, _= get_tfm_datasets(128, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(sz, val_pct, bs):\n",
    "    return DataBunch.create(*get_tfm_datasets(sz, val_pct), bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(128, val_pct=0.2, bs=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "nn.functional.grid_sample got unsupported mode: 'nearest'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-113-2d7feac4e5dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mimgx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimgy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_tds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mimgx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimgy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\vision\\data.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_tfms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtfms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtfm_y\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_tfms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtfms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\vision\\image.py\u001b[0m in \u001b[0;36mapply_tfms\u001b[1;34m(tfms, x, do_resolve, xtra, size, mult, resize_method, padding_mode, **kwargs)\u001b[0m\n\u001b[0;32m    592\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mtfm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msize_tfms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mresize_method\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mResizeMethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCROP\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mResizeMethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPAD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m                     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    595\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\vision\\image.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m->\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m         \u001b[1;34m\"Randomly execute our tfm on `x`.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtfm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresolved\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_run\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_resolve_tfms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mTfmList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\vision\\image.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, p, is_random, *args, **kwargs)\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_random\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mAny\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m->\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[1;34m\"Calc now if `args` passed; else create a transform called prob `p` if `random`.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mRandTransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_random\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_random\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\vision\\image.py\u001b[0m in \u001b[0;36mcalc\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    444\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcalc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mAny\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m->\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m         \u001b[1;34m\"Apply to image `x`, wrapping it if necessary.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrap\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m          \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\vision\\image.py\u001b[0m in \u001b[0;36mpixel\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpixel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mPixelFunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m->\u001b[0m\u001b[1;34m'Image'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[1;34m\"Equivalent to `image.px = func(image.px)`.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\vision\\image.py\u001b[0m in \u001b[0;36mpx\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m->\u001b[0m\u001b[0mTensorImage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;34m\"Get the tensor pixel buffer.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_px\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mpx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\vision\\image.py\u001b[0m in \u001b[0;36mrefresh\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mode'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'nearest'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\vision\\image.py\u001b[0m in \u001b[0;36mrefresh\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_logit_px\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_affine_mat\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flow\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_px\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_grid_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_px\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\vision\\image.py\u001b[0m in \u001b[0;36m_grid_sample\u001b[1;34m(x, coords, mode, padding_mode, **kwargs)\u001b[0m\n\u001b[0;32m    503\u001b[0m     \u001b[1;34m\"Grab pixels in `coords` from `input` sampling by `mode`. `paddding_mode` is reflection, border or zeros.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m     \u001b[0mcoords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# optimize layout for grid_sample\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 505\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_affine_grid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mTensorImageSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m->\u001b[0m\u001b[0mFlowField\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mgrid_sample\u001b[1;34m(input, grid, mode, padding_mode)\u001b[0m\n\u001b[0;32m   2084\u001b[0m     \"\"\"\n\u001b[0;32m   2085\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'bilinear'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2086\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nn.functional.grid_sample got unsupported mode: '{}'\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2087\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpadding_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'zeros'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2088\u001b[0m         \u001b[0mpadding_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGRID_SAMPLE_MODE_ZEROS\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: nn.functional.grid_sample got unsupported mode: 'nearest'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x1152 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_,axes = plt.subplots(5,4, figsize=(12,16))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    imgx,imgy = train_tds[i]\n",
    "    imgx.show(ax, y=imgy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(input:Tensor, targs:Tensor) -> Rank0Tensor:\n",
    "    \"IoU coefficient metric for binary target.\"\n",
    "    n = targs.shape[0]\n",
    "    input = input.argmax(dim=1).view(n,-1)\n",
    "    targs = targs.view(n,-1)\n",
    "    intersect = (input*targs).sum().float()\n",
    "    union = (input+targs).sum().float()\n",
    "    return intersect / (union-intersect+1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=[accuracy, iou]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load resnet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained(model, path):\n",
    "    weights = torch.load(path, map_location=lambda storage, loc: storage)\n",
    "    model.load_state_dict(weights, strict=False)     \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from fastai.vision.models.unet import *\n",
    "body = create_body(tvm.resnet34(True), -2) #/root/.torch/models/\n",
    "body = load_pretrained(body, 'models/0.pth')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DynamicUnet(tvm.resnet34(True), n_classes=2).cuda()\n",
    "\n",
    "learn = Learner(data, model, metrics=metrics,\n",
    "                loss_fn=CrossEntropyFlat())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#((val_x,trn_x),(val_y,trn_y)) = split_by_idx(val_idxs, x_names, y_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model and fitting for size 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=4e-3\n",
    "wd=1e-8\n",
    "\n",
    "lrs = np.array([lr/9,lr/3,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lr,1,wds=wd,cycle_len=6,use_clr=(4, 6), best_save_name='unet_128_xe_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('unet_128_6e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lr,1,wds=wd,cycle_len=10,use_clr=(4, 5), best_save_name='unet_128_xe_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('unet_128_16e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('unet_128_8e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = np.array([lr/9,lr/3,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs,1,cycle_len=5,use_clr=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('unet_128_5e_unfrozen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs,1,cycle_len=8,use_clr=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('unet_128_13e_unfrozen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation with trained resnet layers size 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(data.test_dl))\n",
    "py = to_np(learn.model(V(x)))\n",
    "\n",
    "#x,y = next(iter(data.val_dl))\n",
    "#py = to_np(learn.model(V(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 63):\n",
    "    if len(py[i][py[i]>0]):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = show_img(denorm(x)[idx])\n",
    "show_img(y[idx], ax=ax, alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = show_img(denorm(x)[idx])\n",
    "show_img(py[idx]>0, ax=ax, alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## size 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 32\n",
    "sz = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = tfms_from_model(arch, sz, crop_type=CropType.NO, tfm_y=TfmType.CLASS, aug_tfms=aug_tfms)\n",
    "datasets = ImageData.get_ds(MatchedFilesDataset, (trn_x,trn_y), (val_x,val_y), tfms, test=(x_test_names, y_test_names), path='')\n",
    "data = ImageData(PATH, datasets, bs, num_workers=4, classes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denorm = data.trn_ds.denorm\n",
    "x,y = next(iter(data.aug_dl))\n",
    "x = denorm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 6, figsize=(12, 10))\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    ax=show_img(x[i], ax=ax)\n",
    "    show_img(y[i], ax=ax, alpha=0.5)\n",
    "plt.tight_layout(pad=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_base = get_base()\n",
    "m = to_gpu(Unet34(m_base))\n",
    "models = UnetModel(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner(data, models)\n",
    "learn.opt_fn=optim.Adam\n",
    "learn.crit=nn.BCEWithLogitsLoss()\n",
    "learn.metrics=[accuracy_thresh(0.5), IoU]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find(start_lr=1e-8)\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lr,1,cycle_len=3,use_clr=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('unet_256_3e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lr,1,cycle_len=5,use_clr=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('unet_256_8e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('unet_256_8e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = np.array([lr/9,lr/3,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs,1,cycle_len=3,use_clr=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('unet_256_3e_unfrozen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs,1,cycle_len=5,use_clr=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('unet_256_8e_unfrozen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation with trained resnet layers size 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(data.test_dl))\n",
    "py = to_np(learn.model(V(x)))\n",
    "\n",
    "#x,y = next(iter(data.val_dl))\n",
    "#py = to_np(learn.model(V(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 31):\n",
    "    if len(py[i][py[i]>0]):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = show_img(denorm(x)[idx])\n",
    "show_img(y[idx], ax=ax, alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = show_img(denorm(x)[idx])\n",
    "show_img(py[idx]>0, ax=ax, alpha=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## size 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 11\n",
    "sz = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = tfms_from_model(arch, sz, crop_type=CropType.NO, tfm_y=TfmType.CLASS, aug_tfms=aug_tfms)\n",
    "datasets = ImageData.get_ds(MatchedFilesDataset, (trn_x,trn_y), (val_x,val_y), tfms, test=(x_test_names, y_test_names), path='')\n",
    "data = ImageData(PATH, datasets, bs, num_workers=8, classes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denorm = data.trn_ds.denorm\n",
    "x,y = next(iter(data.aug_dl))\n",
    "x = denorm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(12, 10))\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    ax=show_img(x[i], ax=ax)\n",
    "    show_img(y[i], ax=ax, alpha=0.5)\n",
    "plt.tight_layout(pad=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_base = get_base()\n",
    "m = to_gpu(Unet34(m_base))\n",
    "models = UnetModel(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner(data, models)\n",
    "learn.opt_fn=optim.Adam\n",
    "learn.crit=nn.BCEWithLogitsLoss()\n",
    "learn.metrics=[accuracy_thresh(0.5), IoU]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('unet_256_8e_unfrozen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find(start_lr=1e-8)\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lr,1,cycle_len=3,use_clr=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('unet_512_3e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lr,1,cycle_len=5,use_clr=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('unet_512_8e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('unet_512_8e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = np.array([lr/9,lr/3,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs,1,cycle_len=3,use_clr=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('unet_512_3e_unfrozen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('unet_512_3e_unfrozen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.summary()\n",
    "#learn.get_layer_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs,1,cycle_len=5,use_clr=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('unet_512_8e_unfrozen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation with trained resnet layers size 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x,y = next(iter(data.test_dl))\n",
    "py = to_np(learn.model(V(x)))\n",
    "\n",
    "#x,y = next(iter(data.val_dl))\n",
    "#py = to_np(learn.model(V(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 11):\n",
    "    if len(py[i][py[i]>0]):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = show_img(denorm(x)[idx])\n",
    "show_img(y[idx], ax=ax, alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = show_img(denorm(x)[idx])\n",
    "show_img(py[idx]>0, ax=ax, alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## size 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 4\n",
    "sz = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = tfms_from_model(arch, sz, crop_type=CropType.NO, tfm_y=TfmType.CLASS, aug_tfms=aug_tfms)\n",
    "datasets = ImageData.get_ds(MatchedFilesDataset, (trn_x,trn_y), (val_x,val_y), tfms, test=(x_test_names, y_test_names), path='')\n",
    "data = ImageData(PATH, datasets, bs, num_workers=8, classes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denorm = data.trn_ds.denorm\n",
    "x,y = next(iter(data.aug_dl))\n",
    "x = denorm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    ax=show_img(x[i], ax=ax)\n",
    "    show_img(y[i], ax=ax, alpha=0.5)\n",
    "plt.tight_layout(pad=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def IoU(pred, targs):\n",
    "    pred = (pred > 0).astype(float)\n",
    "    intersection = (pred*targs).sum()\n",
    "    return intersection / ((pred+targs).sum() - intersection + 1.0)\n",
    "'''\n",
    "def iou(input, targs):\n",
    "    \"IoU coefficient metric for binary target.\"\n",
    "    n = targs.shape[0]\n",
    "    input = input.argmax(dim=1).view(n,-1)\n",
    "    targs = targs.view(n,-1)\n",
    "    intersect = (input*targs).sum().float()\n",
    "    union = (input+targs).sum().float()\n",
    "    return intersect / (union-intersect+1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_base = get_base()\n",
    "m = to_gpu(Unet34(m_base))\n",
    "models = UnetModel(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner(data, models)\n",
    "learn.opt_fn=optim.Adam\n",
    "learn.crit=nn.BCEWithLogitsLoss()\n",
    "learn.metrics=[accuracy_thresh(0.5), IoU]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('unet_512_8e_unfrozen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find(start_lr=1e-8)\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.fit(lr,1,cycle_len=2,use_clr=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('unet_768_2e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs,1,cycle_len=3,use_clr=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('unet_768_3e_unfrozen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('unet_768_3e_unfrozen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = np.array([lr/9,lr/3,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.lr_find(start_lr=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs,1,cycle_len=3,use_clr=(20,5), best_save_name='unet_768_xe_best_unfrozen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('unet_768_6e_unfrozen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs,1,cycle_len=3,use_clr=(20,5), best_save_name='unet_768_xe_best2_unfrozen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('unet_768_9e_unfrozen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation with trained resnet layers size 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('unet_768_3e_unfrozen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x,y = next(iter(data.test_dl))\n",
    "py = to_np(learn.model(V(x)))\n",
    "\n",
    "#x,y = next(iter(data.val_dl))\n",
    "#py = to_np(learn.model(V(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 8):\n",
    "    if len(py[i][py[i]>0]):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = show_img(denorm(x)[idx])\n",
    "show_img(y[idx], ax=ax, alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = show_img(denorm(x)[idx])\n",
    "show_img(py[idx]>0, ax=ax, alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# TODO: refacter with this function\n",
    "\n",
    "def get_learner(sz=128, bs=128):\n",
    "    tfms = tfms_from_model(arch, sz, crop_type=CropType.NO, tfm_y=TfmType.CLASS, aug_tfms=aug_tfms)\n",
    "    datasets = ImageData.get_ds(MatchedFilesDataset, (trn_x,trn_y), (val_x,val_y), tfms, test=(x_test_names, y_test_names), path='')\n",
    "    data = ImageData(PATH, datasets, bs, num_workers=4, classes=None)\n",
    "    \n",
    "    models = ConvnetBuilder(arch, 0, 0, 0, custom_head=simple_up)\n",
    "    learn = ConvLearner(data, models)\n",
    "    learn.opt_fn=optim.Adam\n",
    "    learn.crit=nn.BCEWithLogitsLoss()\n",
    "    learn.metrics=[accuracy_thresh(0.5), IoU]\n",
    "\n",
    "    return learn'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction for each ship so we have to split (thanks Iafoss for these convenient functions!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_test(yps, names):\n",
    "    for i in range(len(yps)):\n",
    "        if len(yps[i][yps[i]>0]) > 0:\n",
    "            masks = split_mask(yps[i])\n",
    "            if len(masks) == 0:\n",
    "                print('no mask returned!')\n",
    "                ship_list_dict.append({'ImageId':names[i],'EncodedPixels':''})\n",
    "            for mask in masks:\n",
    "                ship_list_dict.append({'ImageId':names[i],'EncodedPixels':rle_encode(mask)})\n",
    "        else: \n",
    "            ship_list_dict.append({'ImageId':names[i],'EncodedPixels':''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_mask(mask):\n",
    "    threshold = 0\n",
    "    threshold_obj = 0 #ignore predictions composed of \"threshold_obj\" pixels or less\n",
    "    labled,n_objs = ndimage.label(mask > threshold)\n",
    "    result = []\n",
    "    for i in range(n_objs):\n",
    "        obj = (labled == i + 1).astype(int)\n",
    "        #if(obj.sum() > threshold_obj): \n",
    "        result.append(obj)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('unet_768_3e_unfrozen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_length = int(math.ceil((len(data.test_ds)/bs)/30)) #split into 30 batches because of ram limitation\n",
    "\n",
    "mb = master_bar(range(30))\n",
    "mb.first_bar.comment = f'progress on test-set'\n",
    "\n",
    "test_iter = iter(data.test_dl)\n",
    "\n",
    "ship_list_dict = []\n",
    "py = np.empty((0, 768, 768), float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''try:\n",
    "    for i in mb:\n",
    "        for j in progress_bar(range(batch_length), parent=mb):\n",
    "            x,y = next(test_iter)\n",
    "            py = np.append(py, to_np(learn.model(V(x))), axis=0)\n",
    "        f_names = data.test_ds.fnames[batch_length * bs * i:batch_length * bs * (i+1)]\n",
    "        enc_test(py, f_names)\n",
    "        py = np.empty((0, 768, 768), float)\n",
    "except StopIteration:\n",
    "    pass'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "while True:\n",
    "    print(i)\n",
    "    x,y = next(test_iter)\n",
    "    py = np.append(py, to_np(learn.model(V(x))), axis=0)\n",
    "    \n",
    "    f_names = data.test_ds.fnames[i:i+bs]\n",
    "    enc_test(py, f_names)\n",
    "    py = np.empty((0, 768, 768), float)\n",
    "    i += bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ship_list_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(ship_list_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.ImageId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(data.test_ds.fnames)) - pred_df.ImageId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pred_df), len(pred_df.groupby('ImageId', axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir(images_test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(os.listdir(images_test_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(pred_df.ImageId.astype(str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(os.listdir(images_test_path)).difference(set(data.test_ds.fnames)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.ImageId = pred_df.ImageId.apply(lambda x: str(x).split('\\\\')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
