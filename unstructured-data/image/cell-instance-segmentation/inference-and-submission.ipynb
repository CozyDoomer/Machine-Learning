{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Version-history\" data-toc-modified-id=\"Version-history-0.0.0.1\"><span class=\"toc-item-num\">0.0.0.1&nbsp;&nbsp;</span>Version history</a></span></li></ul></li></ul></li><li><span><a href=\"#Inference-and-Submission\" data-toc-modified-id=\"Inference-and-Submission-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span>Inference and Submission</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Install-detectron-2\" data-toc-modified-id=\"Install-detectron-2-0.1.0.1\"><span class=\"toc-item-num\">0.1.0.1&nbsp;&nbsp;</span>Install detectron 2</a></span></li><li><span><a href=\"#Input-dataset\" data-toc-modified-id=\"Input-dataset-0.1.0.2\"><span class=\"toc-item-num\">0.1.0.2&nbsp;&nbsp;</span>Input dataset</a></span></li><li><span><a href=\"#Initiate-a-Predictor-from-the-trained-models\" data-toc-modified-id=\"Initiate-a-Predictor-from-the-trained-models-0.1.0.3\"><span class=\"toc-item-num\">0.1.0.3&nbsp;&nbsp;</span>Initiate a Predictor from the trained models</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Inference\" data-toc-modified-id=\"Inference-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Inference</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Create-the-submission.csv\" data-toc-modified-id=\"Create-the-submission.csv-1.0.0.1\"><span class=\"toc-item-num\">1.0.0.1&nbsp;&nbsp;</span>Create the submission.csv</a></span></li></ul></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is based on Slawek Biel's notebook (https://www.kaggle.com/slawekbiel/positive-score-with-detectron-3-3-inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version history\n",
    "* V1 - test the model_best_5.pth\n",
    "* V2 - test the model_best_4.pth\n",
    "* V3 - test the model_final_6.pth\n",
    "* V4 - test the model_final_5.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference and Submission\n",
    "After training the model ,we can inference with our trained models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install detectron 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement detectron (from versions: none)\u001b[0m\r\n",
      "\u001b[31mERROR: No matching distribution found for detectron\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install detectron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-12-28T04:59:16.197037Z",
     "iopub.status.busy": "2021-12-28T04:59:16.196213Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install ../input/detectron-05/whls/pycocotools-2.0.2/dist/pycocotools-2.0.2.tar --no-index --find-links ../input/detectron-05/whls \n",
    "!pip install ../input/detectron-05/whls/fvcore-0.1.5.post20211019/fvcore-0.1.5.post20211019 --no-index --find-links ../input/detectron-05/whls \n",
    "!pip install ../input/detectron-05/whls/antlr4-python3-runtime-4.8/antlr4-python3-runtime-4.8 --no-index --find-links ../input/detectron-05/whls \n",
    "!pip install ../input/detectron-05/whls/detectron2-0.5/detectron2 --no-index --find-links ../input/detectron-05/whls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import detectron2\n",
    "import torch\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from fastcore.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir=Path('../input/sartorius-cell-instance-segmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, masks=[],[]\n",
    "test_names = (dataDir/'test').ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initiate a Predictor from the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg = get_cfg()\n",
    "# cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "# cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "# cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3 \n",
    "# cfg.MODEL.WEIGHTS = os.path.join('../input/detectron2-sartorius-cell-instance-segmentation', \"model_final_11.pth\")\n",
    "# cfg.TEST.DETECTIONS_PER_IMAGE = 1000\n",
    "# predictor = DefaultPredictor(cfg)\n",
    "# THRESHOLDS = [.15, .35, .55]\n",
    "# MIN_PIXELS = [75, 150, 75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [\n",
    "    \"model_0009679.pth\",\n",
    "    \"model_best_4.pth\",\n",
    "    \"model_best_5.pth\",\n",
    "    \"model_best_6.pth\",\n",
    "    \"model_best_7.pth\",\n",
    "    \"model_best_8.pth\",\n",
    "    \"model_best_9.pth\",\n",
    "    \"model_best_10.pth\",\n",
    "    \"model_final_1.pth\",\n",
    "    \"model_final_2.pth\",\n",
    "    \"model_final_4.pth\",\n",
    "    \"model_final_5.pth\",\n",
    "    \"model_final_6.pth\",\n",
    "    \"model_final_7.pth\",\n",
    "    \"model_final_8.pth\",\n",
    "    \"model_final_11.pth\",\n",
    "    \"model_final_12.pth\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config_name = \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"\n",
    "mdl_path = \"../input/dtectron2-models-5fold\"\n",
    "DATA_PATH = \"../input/sartorius-cell-instance-segmentation\"\n",
    "CONFIG = model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "MODELS = []\n",
    "MODEL_NAMES =[]\n",
    "THSS = []\n",
    "ID_TEST = 0\n",
    "SUBM_PATH = f'{DATA_PATH}/test'\n",
    "SINGLE_MODE = False\n",
    "NMS = True\n",
    "IOU_TH = .4\n",
    "THRESHOLDS = [.15, .35, .55]\n",
    "MIN_PIXELS = [75, 150, 75]\n",
    "\n",
    "for weight in weights:\n",
    "    print(weight)\n",
    "    model_name=weight[:-4]\n",
    "    MODEL_NAMES.append(model_name)\n",
    "    THSS.append(THRESHOLDS)\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(CONFIG)\n",
    "    cfg.INPUT.MASK_FORMAT = 'bitmask'\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3 \n",
    "    cfg.MODEL.WEIGHTS = os.path.join('../input/detectron2sartoriuscellinstancesegmentation', weight)\n",
    "    cfg.TEST.DETECTIONS_PER_IMAGE = 1000\n",
    "    MODELS.append(DefaultPredictor(cfg))\n",
    "print(f'all loaded:\\nthresholds: {THSS}\\nmodels: {BEST_MODELS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_decode(mask_rle, shape=(520, 704)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) \n",
    "                       for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo : hi] = 1\n",
    "    return img.reshape(shape)  # Needed to align to RLE direction\n",
    "\n",
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    \n",
    "    '''\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def pred_masks(file_name, path, model, ths, min_pixels):\n",
    "    img = cv2.imread(f'{path}/{file_name}')\n",
    "    output = model(img)\n",
    "    pred_classes = output['instances'].pred_classes.cpu().numpy().tolist()\n",
    "    pred_class = max(set(pred_classes), key=pred_classes.count)\n",
    "    take = output['instances'].scores >= ths[pred_class]\n",
    "    pred_masks = output['instances'].pred_masks[take]\n",
    "    pred_masks = pred_masks.cpu().numpy()\n",
    "    result = []\n",
    "    used = np.zeros(img.shape[:2], dtype=int) \n",
    "    for i, mask in enumerate(pred_masks):\n",
    "        mask = mask * (1 - used)\n",
    "        if mask.sum() >= min_pixels[pred_class]:\n",
    "            used += mask\n",
    "            result.append(rle_encode(mask))\n",
    "    return result\n",
    "\n",
    "def ensemble_preds(file_name, path, models, ths):\n",
    "    img = cv2.imread(f'{path}/{file_name}')\n",
    "    classes = []\n",
    "    scores = []\n",
    "    bboxes = []\n",
    "    masks = []\n",
    "    for i, model in enumerate(models):\n",
    "        output = model(img)\n",
    "        pred_classes = output['instances'].pred_classes.cpu().numpy().tolist()\n",
    "        pred_class = max(set(pred_classes), key=pred_classes.count)\n",
    "        take = output['instances'].scores >= ths[i][pred_class]\n",
    "        classes.extend(output['instances'].pred_classes[take].cpu().numpy().tolist())\n",
    "        scores.extend(output['instances'].scores[take].cpu().numpy().tolist())\n",
    "        bboxes.extend(output['instances'].pred_boxes[take].tensor.cpu().numpy().tolist())\n",
    "        masks.extend(output['instances'].pred_masks[take].cpu().numpy())\n",
    "    assert len(classes) == len(masks) , 'ensemble lenght mismatch'\n",
    "    #scores, classes, bboxes, masks = zip(*sorted(zip(scores, classes, bboxes, masks),reverse=True))\n",
    "    return classes, scores, bboxes, masks\n",
    "\n",
    "def nms_predictions(classes, scores, bboxes, masks, \n",
    "                    iou_th=.5, shape=(520, 704)):\n",
    "    he, wd = shape[0], shape[1]\n",
    "    boxes_list = [[[x[0] / wd, x[1] / he, x[2] / wd, x[3] / he] for x in bboxes]]\n",
    "    scores_list = [[x for x in scores]]\n",
    "    classes_list = [[x for x in classes]]\n",
    "    nms_bboxes, nms_scores, nms_classes = non_maximum_weighted(\n",
    "        boxes_list, \n",
    "        scores_list, \n",
    "        classes_list, \n",
    "        weights=None,\n",
    "        iou_thr=0.3,skip_box_thr=0.0001  \n",
    "    )\n",
    "    nms_masks = []\n",
    "    for s in nms_scores:\n",
    "        nms_masks.append(masks[scores.index(s)])\n",
    "    nms_scores, nms_classes, nms_masks = zip(*sorted(zip(nms_scores, nms_classes, nms_masks), reverse=True))\n",
    "    return nms_classes, nms_scores, nms_masks\n",
    "\n",
    "def ensemble_pred_masks(masks, classes, min_pixels, shape=(520, 704)):\n",
    "    result = []\n",
    "    #pred_class = max(set(classes), key=classes.count)\n",
    "    pred_class = int(max(set(classes), key=classes.count).item())\n",
    "    used = np.zeros(shape, dtype=int) \n",
    "    for i, mask in enumerate(masks):\n",
    "        mask = mask * (1 - used)\n",
    "        if mask.sum() >= min_pixels[pred_class]:\n",
    "            used += mask\n",
    "            result.append(rle_encode(mask))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, scores, bboxes, masks = ensemble_preds(\n",
    "    file_name=test_names[ID_TEST] , \n",
    "    path=SUBM_PATH, \n",
    "    models=MODELS, \n",
    "    ths=THSS\n",
    ")\n",
    "if NMS:\n",
    "    classes, scores, masks = nms_predictions(\n",
    "        classes, \n",
    "        scores, \n",
    "        bboxes,\n",
    "        masks, iou_th=IOU_TH\n",
    "    )\n",
    "encoded_masks = ensemble_pred_masks(masks, classes, min_pixels=MIN_PIXELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(2, 2, figsize=(14, 8))\n",
    "axs[0][0].imshow(cv2.imread(f'{SUBM_PATH}/{test_names[ID_TEST]}'))\n",
    "axs[0][0].axis('off')\n",
    "axs[0][0].set_title(test_names[ID_TEST])\n",
    "for en_mask in encoded_masks_single:\n",
    "    dec_mask = rle_decode(en_mask)\n",
    "    axs[0][1].imshow(np.ma.masked_where(dec_mask == 0, dec_mask))\n",
    "    axs[0][1].axis('off')\n",
    "    axs[0][1].set_title('single model')\n",
    "axs[1][0].imshow(cv2.imread(f'{SUBM_PATH}/{test_names[ID_TEST]}'))\n",
    "axs[1][0].axis('off')\n",
    "axs[1][0].set_title(test_names[ID_TEST])\n",
    "for en_mask in encoded_masks:\n",
    "    dec_mask = rle_decode(en_mask)\n",
    "    axs[1][1].imshow(np.ma.masked_where(dec_mask == 0, dec_mask))\n",
    "    axs[1][1].axis('off')\n",
    "    axs[1][1].set_title('ensemble models')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_ids, subm_masks = [], []\n",
    "for test_name in tqdm(test_names):\n",
    "    if SINGLE_MODE:\n",
    "        encoded_masks = pred_masks(\n",
    "            test_name, \n",
    "            path=SUBM_PATH, \n",
    "            model=MODELS[0],\n",
    "            ths=THSS[0],\n",
    "            min_pixels=MIN_PIXELS\n",
    "        )\n",
    "    else:\n",
    "        classes, scores, bboxes, masks = ensemble_preds(\n",
    "            file_name=test_name, \n",
    "            path=SUBM_PATH, \n",
    "            models=MODELS, \n",
    "            ths=THSS\n",
    "        )\n",
    "        if NMS:\n",
    "            classes, scores, masks = nms_predictions(\n",
    "                classes, \n",
    "                scores, \n",
    "                bboxes, \n",
    "                masks, \n",
    "                iou_th=IOU_TH\n",
    "            )\n",
    "        encoded_masks = ensemble_pred_masks(\n",
    "            masks, \n",
    "            classes, \n",
    "            min_pixels=MIN_PIXELS\n",
    "        )\n",
    "    for enc_mask in encoded_masks:\n",
    "        subm_ids.append(test_name[:test_name.find('.')])\n",
    "        subm_masks.append(enc_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T04:33:00.928675Z",
     "iopub.status.idle": "2021-12-28T04:33:00.929082Z",
     "shell.execute_reply": "2021-12-28T04:33:00.928882Z",
     "shell.execute_reply.started": "2021-12-28T04:33:00.928861Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'id': subm_ids, \n",
    "    'predicted': subm_masks\n",
    "}).to_csv('submission.csv', index=False)\n",
    "pd.read_csv('submission.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T04:33:00.930397Z",
     "iopub.status.idle": "2021-12-28T04:33:00.930898Z",
     "shell.execute_reply": "2021-12-28T04:33:00.930674Z",
     "shell.execute_reply.started": "2021-12-28T04:33:00.930649Z"
    }
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame({'id':ids, 'predicted':masks}).to_csv('submission.csv', index=False)\n",
    "# pd.read_csv('submission.csv').head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
