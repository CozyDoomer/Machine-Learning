{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use stacked images (3D) and Densenet121 3D model\n",
    "\n",
    "Acknowledgements:\n",
    "\n",
    "- https://www.kaggle.com/rluethy/efficientnet3d-with-one-mri-type\n",
    "- https://www.kaggle.com/davidbroberts/determining-dicom-image-order\n",
    "- https://www.kaggle.com/ihelon/brain-tumor-eda-with-animations-and-modeling\n",
    "- https://www.kaggle.com/furcifer/torch-efficientnet3d-for-mri-no-train\n",
    "- https://github.com/shijianjian/EfficientNet-PyTorch-3D\n",
    "\n",
    "This notebook is based on the implementation of Densenet121 3D available here:\n",
    "https://www.kaggle.com/mikecho/monai-v060-deep-learning-in-healthcare-imaging\n",
    "\n",
    "It builds 4 models with only one MRI type, then ensembles all of them computing average probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchio in /home/christian/miniconda/envs/pytorch/lib/python3.8/site-packages (0.18.56)\n",
      "Requirement already satisfied: nibabel in /home/christian/miniconda/envs/pytorch/lib/python3.8/site-packages (from torchio) (3.2.1)\n",
      "Requirement already satisfied: humanize in /home/christian/miniconda/envs/pytorch/lib/python3.8/site-packages (from torchio) (3.11.0)\n",
      "Requirement already satisfied: scipy in /home/christian/miniconda/envs/pytorch/lib/python3.8/site-packages (from torchio) (1.7.1)\n",
      "Requirement already satisfied: tqdm in /home/christian/miniconda/envs/pytorch/lib/python3.8/site-packages (from torchio) (4.62.2)\n",
      "Requirement already satisfied: Deprecated in /home/christian/miniconda/envs/pytorch/lib/python3.8/site-packages (from torchio) (1.2.13)\n",
      "Requirement already satisfied: click in /home/christian/miniconda/envs/pytorch/lib/python3.8/site-packages (from torchio) (8.0.1)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/christian/miniconda/envs/pytorch/lib/python3.8/site-packages (from torchio) (1.21.2)\n",
      "Requirement already satisfied: torch>=1.1 in /home/christian/miniconda/envs/pytorch/lib/python3.8/site-packages (from torchio) (1.10.0.dev20210914)\n",
      "Requirement already satisfied: SimpleITK!=2.0.* in /home/christian/miniconda/envs/pytorch/lib/python3.8/site-packages (from torchio) (2.1.1)\n",
      "Requirement already satisfied: typing_extensions in /home/christian/miniconda/envs/pytorch/lib/python3.8/site-packages (from torch>=1.1->torchio) (3.10.0.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/christian/miniconda/envs/pytorch/lib/python3.8/site-packages (from Deprecated->torchio) (1.12.1)\n",
      "Requirement already satisfied: setuptools in /home/christian/miniconda/envs/pytorch/lib/python3.8/site-packages (from humanize->torchio) (52.0.0.post20210125)\n",
      "Requirement already satisfied: packaging>=14.3 in /home/christian/miniconda/envs/pytorch/lib/python3.8/site-packages (from nibabel->torchio) (21.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/christian/miniconda/envs/pytorch/lib/python3.8/site-packages (from packaging>=14.3->nibabel->torchio) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T16:39:28.897999Z",
     "iopub.status.busy": "2021-09-09T16:39:28.897707Z",
     "iopub.status.idle": "2021-09-09T16:39:31.381066Z",
     "shell.execute_reply": "2021-09-09T16:39:31.380198Z",
     "shell.execute_reply.started": "2021-09-09T16:39:28.897933Z"
    },
    "papermill": {
     "duration": 1.048295,
     "end_time": "2021-07-14T20:26:46.309722",
     "exception": false,
     "start_time": "2021-07-14T20:26:45.261427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import re\n",
    "import collections\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data as torch_data\n",
    "from sklearn import model_selection as sk_model_selection\n",
    "from torch.nn import functional as torch_functional\n",
    "\n",
    "import torchio as tio\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"/kaggle/input/rsna-miccai-brain-tumor-radiogenomic-classification\"):\n",
    "    data_directory = \"/kaggle/input/rsna-miccai-brain-tumor-radiogenomic-classification\"\n",
    "    input_monaipath = \"/kaggle/input/monai-v060-deep-learning-in-healthcare-imaging/\"\n",
    "    landmarks_directory = \"/kaggle/input/rsna-landmarks\"\n",
    "else:\n",
    "    data_directory = \"rsna-miccai-brain-tumor-radiogenomic-classification\"\n",
    "    input_monaipath = \"monai-v060-deep-learning-in-healthcare-imaging\"\n",
    "    landmarks_directory = \"rsna-landmarks\"\n",
    "\n",
    "model_paths = \"models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T16:39:35.258348Z",
     "iopub.status.busy": "2021-09-09T16:39:35.256703Z",
     "iopub.status.idle": "2021-09-09T16:39:37.741004Z",
     "shell.execute_reply": "2021-09-09T16:39:37.740092Z",
     "shell.execute_reply.started": "2021-09-09T16:39:35.258304Z"
    },
    "lines_to_end_of_cell_marker": 2,
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 0.05565,
     "end_time": "2021-07-14T20:26:46.486521",
     "exception": false,
     "start_time": "2021-07-14T20:26:46.430871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mri_types = ['FLAIR', 'T1w', 'T1wCE', 'T2w']\n",
    "SIZE = 256\n",
    "NUM_IMAGES = 64\n",
    "BATCH_SIZE = 2\n",
    "N_EPOCHS = 6\n",
    "NUM_FOLDS = 5\n",
    "SEED = 42\n",
    "MIN_LR = 1e-8\n",
    "LR = 1e-4\n",
    "\n",
    "sys.path.append(input_monaipath)\n",
    "\n",
    "from monai.networks.nets.densenet import DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOTAL_EPOCHS = N_EPOCHS * len(mri_types) * NUM_FOLDS\n",
    "TOTAL_EPOCHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T16:39:37.74273Z",
     "iopub.status.busy": "2021-09-09T16:39:37.742391Z",
     "iopub.status.idle": "2021-09-09T16:39:38.474379Z",
     "shell.execute_reply": "2021-09-09T16:39:38.47359Z",
     "shell.execute_reply.started": "2021-09-09T16:39:37.742695Z"
    },
    "papermill": {
     "duration": 0.035761,
     "end_time": "2021-07-14T20:26:46.726756",
     "exception": false,
     "start_time": "2021-07-14T20:26:46.690995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def load_dicom_image(path, img_size=SIZE):\n",
    "#     dicom = pydicom.read_file(path)\n",
    "#     data = dicom.pixel_array\n",
    "#     if np.min(data)==np.max(data):\n",
    "#         data = np.zeros((img_size,img_size))\n",
    "#         return data\n",
    "#     \n",
    "#     data = cv2.resize(data, (img_size, img_size))\n",
    "#     return data\n",
    "# \n",
    "# \n",
    "# def natural_sort(l): \n",
    "#     convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
    "#     alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n",
    "#     return sorted(l, key=alphanum_key)\n",
    "# \n",
    "# \n",
    "# def load_dicom_images_3d(scan_id, num_imgs=NUM_IMAGES, img_size=SIZE, mri_type=\"FLAIR\", split=\"train\"):\n",
    "#     files = natural_sort(glob.glob(f\"{data_directory}/{split}/{scan_id}/{mri_type}/*.dcm\"))\n",
    "#     every_nth = len(files) / num_imgs\n",
    "#     indexes = [min(int(round(i*every_nth)), len(files)-1) for i in range(0,num_imgs)]\n",
    "#     \n",
    "#     files_to_load = [files[i] for i in indexes]\n",
    "#     \n",
    "#     img3d = np.stack([load_dicom_image(f) for f in files_to_load]).T \n",
    "#     \n",
    "#     img3d = img3d - np.min(img3d)\n",
    "#     if np.max(img3d) != 0:\n",
    "#         img3d = img3d / np.max(img3d)\n",
    "#     \n",
    "#     return np.expand_dims(img3d,0)\n",
    "# \n",
    "# \n",
    "# load_dicom_images_3d(\"00000\", mri_type=mri_types[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T16:39:38.477343Z",
     "iopub.status.busy": "2021-09-09T16:39:38.477088Z",
     "iopub.status.idle": "2021-09-09T16:39:38.539718Z",
     "shell.execute_reply": "2021-09-09T16:39:38.538874Z",
     "shell.execute_reply.started": "2021-09-09T16:39:38.477318Z"
    },
    "papermill": {
     "duration": 0.668331,
     "end_time": "2021-07-14T20:27:48.114522",
     "exception": false,
     "start_time": "2021-07-14T20:27:47.446191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove samples as described in https://www.kaggle.com/c/rsna-miccai-brain-tumor-radiogenomic-classification/discussion/262046"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T16:39:38.542555Z",
     "iopub.status.busy": "2021-09-09T16:39:38.54223Z",
     "iopub.status.idle": "2021-09-09T16:39:38.581634Z",
     "shell.execute_reply": "2021-09-09T16:39:38.580917Z",
     "shell.execute_reply.started": "2021-09-09T16:39:38.542521Z"
    },
    "papermill": {
     "duration": 0.633753,
     "end_time": "2021-07-14T20:27:49.350524",
     "exception": false,
     "start_time": "2021-07-14T20:27:48.716771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original shape (585, 2)\n"
     ]
    }
   ],
   "source": [
    "# samples_to_exclude = [109, 123, 709]\n",
    "# \n",
    "df = pd.read_csv(f\"{data_directory}/train_labels.csv\")\n",
    "print(\"original shape\", df.shape)\n",
    "# df = df[~df.BraTS21ID.isin(samples_to_exclude)]\n",
    "# print(\"new shape\", df.shape)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.iloc[:16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and training classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# landmarks = torch.load(os.path.join(landmarks_directory, (f\"{mri_type}_landmarks.npy\")))\n",
    "# landmarks_dict = {\n",
    "#     \"default_image_name\": landmarks,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [\n",
    "    # tio.HistogramStandardization(landmarks_dict),\n",
    "    tio.ToCanonical(),\n",
    "    tio.Resample(1, image_interpolation='bspline'),\n",
    "    tio.Resample('T1w', image_interpolation='nearest'),\n",
    "    tio.RandomAnisotropy(p=0.25),              # make images look anisotropic 25% of times\n",
    "    # TODO: crop only sometimes! this happens all the time which is risky\n",
    "    # tio.CropOrPad((256, 256, 64)),            # tight crop around brain\n",
    "    # TODO: calculate landmarks:\n",
    "    # https://colab.research.google.com/github/fepegar/torchio-notebooks/blob/main/notebooks/Data_preprocessing_and_augmentation_using_TorchIO_a_tutorial.ipynb#scrollTo=85COw2H63PfH\n",
    "    # too strong? (removes part of the scan!)\n",
    "    # tio.ZNormalization(\n",
    "    #     masking_method=get_foreground),        # zero mean, unit variance of foreground\n",
    "    #   works!\n",
    "    tio.RandomBlur(p=0.25),                    # blur 25% of times\n",
    "    tio.RandomNoise(p=0.25),                   # Gaussian noise 25% of times\n",
    "    tio.OneOf({                                # either\n",
    "        tio.RandomAffine(): 0.8,               # random affine\n",
    "        tio.RandomElasticDeformation(): 0.2,   # or random elastic deformation\n",
    "    }, p=0.8),                                 # applied to 80% of images\n",
    "    tio.RandomBiasField(p=0.3),                # magnetic field inhomogeneity 30% of times\n",
    "    tio.OneOf({                                # either\n",
    "        tio.RandomMotion(): 1,                 # random motion artifact\n",
    "        tio.RandomSpike(): 2,                  # or spikes\n",
    "        tio.RandomGhosting(): 2,               # or ghosts\n",
    "    }, p=0.5),                                 # applied to 50% of images\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = tio.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pathlib import Path\n",
    "\n",
    "class RSNAMICCAI(tio.data.dataset.SubjectsDataset):\n",
    "    \"\"\"RSNA-MICCAI Brain Tumor Radiogenomic Classification challenge dataset.\n",
    "\n",
    "    This is a helper class for the dataset used in the\n",
    "    `RSNA-MICCAI Brain Tumor Radiogenomic Classification challenge`_ hosted on\n",
    "    `kaggle <https://www.kaggle.com/>`_. The dataset must be downloaded before\n",
    "    instantiating this class (as oposed to, e.g., :class:`torchio.datasets.IXI`).\n",
    "\n",
    "    This `kaggle kernel <https://www.kaggle.com/fepegar/preprocessing-mri-with-torchio/>`_\n",
    "    includes a usage example including preprocessing of all the scans.\n",
    "\n",
    "    If you reference or use the dataset in any form, include the following\n",
    "    citation:\n",
    "\n",
    "    U.Baid, et al., \"The RSNA-ASNR-MICCAI BraTS 2021 Benchmark on Brain Tumor\n",
    "    Segmentation and Radiogenomic Classification\", arXiv:2107.02314, 2021.\n",
    "\n",
    "    Args:\n",
    "        root_dir: Directory containing the dataset (``train`` directory,\n",
    "            ``test`` directory, etc.).\n",
    "        train: If ``True``, the ``train`` set will be used. Otherwise the\n",
    "            ``test`` set will be used.\n",
    "        ignore_empty: If ``True``, the three subjects flagged as \"presenting\n",
    "            issues\" (empty images) by the challenge organizers will be ignored.\n",
    "            The subject IDs are ``00109``, ``00123`` and ``00709``.\n",
    "\n",
    "    Example:\n",
    "        >>> import torchio as tio\n",
    "        >>> from subprocess import call\n",
    "        >>> call('kaggle competitions download -c rsna-miccai-brain-tumor-radiogenomic-classification'.split())\n",
    "        >>> root_dir = 'rsna-miccai-brain-tumor-radiogenomic-classification'\n",
    "        >>> train_set = tio.datasets.RSNAMICCAI(root_dir, train=True)\n",
    "        >>> test_set = tio.datasets.RSNAMICCAI(root_dir, train=False)\n",
    "        >>> len(train_set), len(test_set)\n",
    "        (582, 87)\n",
    "\n",
    "\n",
    "    .. _RSNA-MICCAI Brain Tumor Radiogenomic Classification challenge: https://www.kaggle.com/c/rsna-miccai-brain-tumor-radiogenomic-classification\n",
    "    \"\"\"  # noqa: E501\n",
    "    id_key = 'BraTS21ID'\n",
    "    label_key = 'MGMT_value'\n",
    "    modalities = 'T1w', 'T1wCE', 'T2w', 'FLAIR'\n",
    "    bad_subjects = '00109', '00123', '00709'\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            root_dir,\n",
    "            df,\n",
    "            train: bool = True,\n",
    "            ignore_empty: bool = True,\n",
    "            **kwargs,\n",
    "            ):\n",
    "        self.root_dir = Path(root_dir).expanduser().resolve()\n",
    "        self.df = df\n",
    "        subjects = self._get_subjects(self.root_dir, train, ignore_empty)\n",
    "        super().__init__(subjects, **kwargs)\n",
    "        self.train = train\n",
    "\n",
    "    def _get_subjects(\n",
    "            self,\n",
    "            root_dir: Path,\n",
    "            train: bool,\n",
    "            ignore_empty: bool,\n",
    "            ) -> List[tio.data.Subject]:\n",
    "        subjects = []\n",
    "        if train:\n",
    "            labels_dict = {\n",
    "                brats_id: mgmt_value\n",
    "                for brats_id, mgmt_value in zip(\n",
    "                    np.array([str(x).zfill(5) for x in self.df.BraTS21ID.values]),\n",
    "                    self.df.MGMT_value.values\n",
    "                )\n",
    "            }\n",
    "            subjects_dir = root_dir / 'train'\n",
    "        else:\n",
    "            subjects_dir = root_dir / 'test'\n",
    "\n",
    "        for subject_id in sorted(labels_dict):\n",
    "            if ignore_empty and subject_id in self.bad_subjects:\n",
    "                continue\n",
    "            try:\n",
    "                int(subject_id)\n",
    "            except ValueError:\n",
    "                continue\n",
    "            images_dict = {self.id_key: subject_id}\n",
    "            if train:\n",
    "                images_dict[self.label_key] = labels_dict[subject_id]\n",
    "            for modality in self.modalities:\n",
    "                image_dir = f'{subjects_dir}/{subject_id}/{modality}'\n",
    "                filepaths = os.listdir(image_dir)\n",
    "                num_files = len(filepaths)\n",
    "                path = filepaths[0] if num_files == 1 else image_dir\n",
    "                images_dict[modality] = tio.data.ScalarImage(path)\n",
    "            subject = tio.data.Subject(images_dict)\n",
    "            subjects.append(subject)\n",
    "        return subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import csv\n",
    "# csv_path = f'{data_directory}/train_labels.csv'\n",
    "# with open(csv_path) as csvfile:\n",
    "#     reader = csv.DictReader(csvfile)\n",
    "#     labels_dict = {\n",
    "#         row['BraTS21ID']: int(row['MGMT_value'])\n",
    "#         for row in reader\n",
    "#     }\n",
    "# labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T16:39:38.610499Z",
     "iopub.status.busy": "2021-09-09T16:39:38.610156Z",
     "iopub.status.idle": "2021-09-09T16:39:38.618176Z",
     "shell.execute_reply": "2021-09-09T16:39:38.617273Z",
     "shell.execute_reply.started": "2021-09-09T16:39:38.610472Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = DenseNet121(spatial_dims=3, in_channels=1, out_channels=1)\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T16:39:38.62031Z",
     "iopub.status.busy": "2021-09-09T16:39:38.619784Z",
     "iopub.status.idle": "2021-09-09T16:39:38.647541Z",
     "shell.execute_reply": "2021-09-09T16:39:38.646658Z",
     "shell.execute_reply.started": "2021-09-09T16:39:38.620272Z"
    },
    "papermill": {
     "duration": 0.637077,
     "end_time": "2021-07-14T20:27:58.09407",
     "exception": false,
     "start_time": "2021-07-14T20:27:57.456993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "        self, \n",
    "        model, \n",
    "        device, \n",
    "        optimizer, \n",
    "        criterion\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.optimizer = optimizer\n",
    "        self.lr_scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=MIN_LR, max_lr=LR, cycle_momentum=False)\n",
    "        # self.lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=LR_DECAY)\n",
    "        self.criterion = criterion\n",
    "\n",
    "        self.best_valid_score = .0\n",
    "        self.n_patience = 0\n",
    "        self.lastmodel = None\n",
    "        \n",
    "        self.val_losses = []\n",
    "        self.train_losses = []\n",
    "        self.val_auc = []\n",
    "        \n",
    "    def fit(self, epochs, train_loader, valid_loader, save_path, patience):      \n",
    "        for n_epoch in range(1, epochs + 1):\n",
    "            self.info_message(\"EPOCH: {}\", n_epoch)\n",
    "            \n",
    "            train_loss, train_time = self.train_epoch(train_loader)\n",
    "            valid_loss, valid_auc, valid_time = self.valid_epoch(valid_loader)\n",
    "            \n",
    "            self.train_losses.append(train_loss)\n",
    "            self.val_losses.append(valid_loss)\n",
    "            self.val_auc.append(valid_auc)\n",
    "            \n",
    "            self.info_message(\n",
    "                \"[Epoch Train: {}] loss: {:.4f}, time: {:.2f} s\",\n",
    "                n_epoch, train_loss, train_time\n",
    "            )\n",
    "            \n",
    "            self.info_message(\n",
    "                \"[Epoch Valid: {}] loss: {:.4f}, auc: {:.4f}, time: {:.2f} s\",\n",
    "                n_epoch, valid_loss, valid_auc, valid_time\n",
    "            )\n",
    "\n",
    "            if self.best_valid_score < valid_auc: \n",
    "                self.save_model(n_epoch, save_path, valid_loss, valid_auc)\n",
    "                self.info_message(\n",
    "                     \"auc improved from {:.4f} to {:.4f}. Saved model to '{}'\", \n",
    "                    self.best_valid_score, valid_auc, self.lastmodel\n",
    "                )\n",
    "                self.best_valid_score = valid_auc\n",
    "                self.n_patience = 0\n",
    "            else:\n",
    "                self.n_patience += 1\n",
    "            \n",
    "            if self.n_patience >= patience:\n",
    "                self.info_message(\"\\nValid auc didn't improve last {} epochs.\", patience)\n",
    "                break\n",
    "            \n",
    "    def train_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "        t = time.time()\n",
    "        sum_loss = 0\n",
    "\n",
    "        for step, batch in enumerate(train_loader, 1):\n",
    "            samples = []\n",
    "            for sample in batch[\"X\"]:\n",
    "                \n",
    "            batch[\"X\"] = cv2.resize(batch[\"X\"], (SIZE, SIZE))\n",
    "            X = batch[\"X\"].clone().detach().float().to(self.device)\n",
    "            targets = batch[\"y\"].to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(X).squeeze(1)\n",
    "            loss = self.criterion(outputs, targets)\n",
    "                \n",
    "            loss.backward()\n",
    "\n",
    "            sum_loss += loss.detach().item()\n",
    "            \n",
    "            self.optimizer.step()\n",
    "            # for param_group in self.optimizer.param_groups:\n",
    "            #     print(param_group['lr'])\n",
    "            \n",
    "            message = 'Train Step {}/{}, train_loss: {:.4f}'\n",
    "            self.info_message(message, step, len(train_loader), sum_loss/step, end=\"\\r\")\n",
    "            \n",
    "        self.lr_scheduler.step()\n",
    "        \n",
    "        return sum_loss/len(train_loader), int(time.time() - t)\n",
    "    \n",
    "    def valid_epoch(self, valid_loader):\n",
    "        self.model.eval()\n",
    "        t = time.time()\n",
    "        sum_loss = 0\n",
    "        y_all = []\n",
    "        outputs_all = []\n",
    "\n",
    "        for step, batch in enumerate(valid_loader, 1):\n",
    "            with torch.no_grad():\n",
    "                targets = batch[\"y\"].to(self.device)\n",
    "\n",
    "                output = torch.sigmoid(self.model(batch[\"X\"].clone().detach().float().to(self.device)).squeeze(1))\n",
    "                loss = self.criterion(output, targets)\n",
    "                sum_loss += loss.detach().item()\n",
    "\n",
    "                y_all.extend(batch[\"y\"].tolist())\n",
    "                outputs_all.extend(output.tolist())\n",
    "\n",
    "            message = 'Valid Step {}/{}, valid_loss: {:.4f}'\n",
    "            self.info_message(message, step, len(valid_loader), sum_loss/step, end=\"\\r\")\n",
    "            \n",
    "        y_all = [1 if x > 0.5 else 0 for x in y_all]\n",
    "        auc = roc_auc_score(y_all, outputs_all)\n",
    "        \n",
    "        return sum_loss/len(valid_loader), auc, int(time.time() - t)\n",
    "    \n",
    "    def save_model(self, n_epoch, save_path, loss, auc):\n",
    "        self.lastmodel = f\"{save_path}-e{n_epoch}-loss{loss:.3f}-auc{auc:.3f}.pth\"\n",
    "        torch.save(\n",
    "            {\n",
    "                \"model_state_dict\": self.model.state_dict(),\n",
    "                \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "                \"best_valid_score\": self.best_valid_score,\n",
    "                \"n_epoch\": n_epoch,\n",
    "            },\n",
    "            self.lastmodel,\n",
    "        )\n",
    "        \n",
    "    def display_plots(self, mri_type):\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.title(\"{}: Training and Validation Loss\")\n",
    "        plt.plot(self.val_losses,label=\"val\")\n",
    "        plt.plot(self.train_losses,label=\"train\")\n",
    "        plt.xlabel(\"iterations\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.title(\"{}: Validation AUC-ROC\")\n",
    "        plt.plot(self.val_auc,label=\"val\")\n",
    "        plt.xlabel(\"iterations\")\n",
    "        plt.ylabel(\"AUC\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    \n",
    "    @staticmethod\n",
    "    def info_message(message, *args, end=\"\\n\"):\n",
    "        print(message.format(*args), end=end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T16:58:00.520823Z",
     "iopub.status.busy": "2021-09-09T16:58:00.520451Z",
     "iopub.status.idle": "2021-09-09T16:58:00.531215Z",
     "shell.execute_reply": "2021-09-09T16:58:00.530072Z",
     "shell.execute_reply.started": "2021-09-09T16:58:00.520782Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(model, df, dataset, mri_type, split):\n",
    "    print(\"Predict:\", mri_type)\n",
    "    try:\n",
    "        dataset = RSNAMICCAI(data_directory, df, train=True, transform=preprocess)\n",
    "    except:\n",
    "        dataset = RSNAMICCAI(data_directory, df, train=False, transform=preprocess)\n",
    "\n",
    "    data_loader = torch_data.DataLoader(\n",
    "        dataset,\n",
    "        num_workers=mp.cpu_count(),\n",
    "        collate_fn=lambda x: x[0],\n",
    "    )\n",
    "   \n",
    "    model.eval()\n",
    "    \n",
    "    y_pred = []\n",
    "    ids = []\n",
    "\n",
    "    for e, batch in enumerate(data_loader,1):\n",
    "        print(f\"{e}/{len(data_loader)}\", end=\"\\r\")\n",
    "        with torch.no_grad():\n",
    "            tmp_pred = torch.sigmoid(model(batch[\"X\"].clone().detach().float().to(device)).squeeze(1)).cpu().numpy().squeeze()\n",
    "            if tmp_pred.size == 1:\n",
    "                y_pred.append(tmp_pred)\n",
    "            else:\n",
    "                y_pred.extend(tmp_pred.tolist())\n",
    "            ids.extend(batch[\"id\"].numpy().tolist())\n",
    "            \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T16:39:38.649382Z",
     "iopub.status.busy": "2021-09-09T16:39:38.648964Z",
     "iopub.status.idle": "2021-09-09T16:58:00.518805Z",
     "shell.execute_reply": "2021-09-09T16:58:00.517962Z",
     "shell.execute_reply.started": "2021-09-09T16:39:38.649343Z"
    },
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 447.387602,
     "end_time": "2021-07-14T20:35:26.110421",
     "exception": false,
     "start_time": "2021-07-14T20:27:58.722819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train_mri_type(df, df_test, mri_type, skf):\n",
    "\n",
    "    oof_train = np.zeros((len(df)))\n",
    "    oof_test = np.zeros((len(df_test)))\n",
    "    oof_test_skf = np.empty((5, len(df_test)))\n",
    "\n",
    "    lastmodels = []\n",
    "    for i, (train_index, val_index) in enumerate(skf.split(df, df[\"MGMT_value\"], df[\"MGMT_value\"])):\n",
    "        df_train = df.iloc[train_index]\n",
    "        df_valid = df.iloc[val_index]\n",
    "        \n",
    "        train = df_train.copy()\n",
    "        valid = df_valid.copy()\n",
    "        train.loc[:,\"MRI_Type\"] = mri_type\n",
    "        valid.loc[:,\"MRI_Type\"] = mri_type\n",
    "\n",
    "        print(train.shape, valid.shape)\n",
    "        display(valid.head())\n",
    "        print(len(train))\n",
    "        display(valid.head())\n",
    "        print(len(valid))\n",
    "\n",
    "        # landmarks = torch.load(os.path.join(landmarks_directory, (f\"{mri_type}_landmarks.npy\")))\n",
    "        # landmarks_dict = {\n",
    "        #     \"default_image_name\": landmarks,\n",
    "        # }\n",
    "\n",
    "        train_dataset = RSNAMICCAI(data_directory, df_train, train=True, transform=preprocess)\n",
    "        valid_dataset = RSNAMICCAI(data_directory, df_valid, train=True, transform=preprocess)\n",
    "\n",
    "        train_loader = torch_data.DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            num_workers=8,\n",
    "        )\n",
    "\n",
    "        valid_loader = torch_data.DataLoader(\n",
    "            valid_dataset, \n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            num_workers=8,\n",
    "        )\n",
    "\n",
    "        model = build_model()\n",
    "        model.to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "        criterion = torch_functional.binary_cross_entropy_with_logits\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model, \n",
    "            device, \n",
    "            optimizer, \n",
    "            criterion\n",
    "        )\n",
    "\n",
    "        os.makedirs(f\"models/fold_{i}\", exist_ok=True)\n",
    "        history = trainer.fit(\n",
    "            N_EPOCHS, \n",
    "            train_loader, \n",
    "            valid_loader, \n",
    "            f\"{model_paths}/fold_{i}/{mri_type}\", \n",
    "            N_EPOCHS,\n",
    "        )\n",
    "\n",
    "        trainer.display_plots(mri_type)\n",
    "\n",
    "        oof_train[val_index] = predict(model, df_valid, mri_type, \"train\")\n",
    "        oof_test_skf[i, :] = predict(model, df_test, mri_type, \"test\")\n",
    "\n",
    "        lastmodels.append(trainer.lastmodel)\n",
    "\n",
    "    oof_test = oof_test_skf.mean(axis=0)\n",
    "\n",
    "    return oof_train, oof_test, lastmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(f\"{data_directory}/sample_submission.csv\")\n",
    "df_test[\"MGMT_value\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "rkf = StratifiedKFold(n_splits=5, shuffle=True, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(468, 3) (117, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BraTS21ID</th>\n",
       "      <th>MGMT_value</th>\n",
       "      <th>MRI_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>FLAIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>FLAIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>FLAIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>FLAIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>FLAIR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    BraTS21ID  MGMT_value MRI_Type\n",
       "2           3           0    FLAIR\n",
       "9          14           1    FLAIR\n",
       "11         18           0    FLAIR\n",
       "18         26           1    FLAIR\n",
       "24         35           1    FLAIR"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BraTS21ID</th>\n",
       "      <th>MGMT_value</th>\n",
       "      <th>MRI_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>FLAIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>FLAIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>FLAIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>FLAIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>FLAIR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    BraTS21ID  MGMT_value MRI_Type\n",
       "2           3           0    FLAIR\n",
       "9          14           1    FLAIR\n",
       "11         18           0    FLAIR\n",
       "18         26           1    FLAIR\n",
       "24         35           1    FLAIR"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\n",
      "EPOCH: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.2/itkImageSeriesReader.hxx, line 480\n",
      "ImageSeriesReader (0x5650f8816830): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.00101728\n",
      "\n",
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.2/itkImageSeriesReader.hxx, line 480\n",
      "ImageSeriesReader (0x5650f8816830): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.000760964\n",
      "\n",
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.2/itkImageSeriesReader.hxx, line 480\n",
      "ImageSeriesReader (0x5650f8816830): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.000298474\n",
      "\n",
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.2/itkImageSeriesReader.hxx, line 480\n",
      "ImageSeriesReader (0x5650f8816830): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.000848286\n",
      "\n",
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.2/itkImageSeriesReader.hxx, line 480\n",
      "ImageSeriesReader (0x5650f8816830): Non uniform sampling or missing slices detected,  maximum nonuniformity:1.97312\n",
      "\n",
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.2/itkImageSeriesReader.hxx, line 480\n",
      "ImageSeriesReader (0x5650f8816830): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.000298474\n",
      "\n",
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.2/itkImageSeriesReader.hxx, line 480\n",
      "ImageSeriesReader (0x5650f8816830): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.000760964\n",
      "\n",
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.2/itkImageSeriesReader.hxx, line 480\n",
      "ImageSeriesReader (0x5650f8816830): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.000848286\n",
      "\n",
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.2/itkImageSeriesReader.hxx, line 480\n",
      "ImageSeriesReader (0x5650f8816830): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.000101789\n",
      "\n",
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.2/itkImageSeriesReader.hxx, line 480\n",
      "ImageSeriesReader (0x5650f8816830): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.000899336\n",
      "\n",
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.2/itkImageSeriesReader.hxx, line 480\n",
      "ImageSeriesReader (0x5650f8816830): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.000821815\n",
      "\n",
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.2/itkImageSeriesReader.hxx, line 480\n",
      "ImageSeriesReader (0x5650f8816830): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.000793209\n",
      "\n",
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.2/itkImageSeriesReader.hxx, line 480\n",
      "ImageSeriesReader (0x5650f8816830): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.000801339\n",
      "\n",
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.2/itkImageSeriesReader.hxx, line 480\n",
      "ImageSeriesReader (0x5650f8816830): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.000801339\n",
      "\n",
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.2/itkImageSeriesReader.hxx, line 480\n",
      "ImageSeriesReader (0x5650f8816830): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.000920953\n",
      "\n",
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.2/itkImageSeriesReader.hxx, line 480\n",
      "ImageSeriesReader (0x5650f8816830): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.000815532\n",
      "\n",
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.2/itkImageSeriesReader.hxx, line 480\n",
      "ImageSeriesReader (0x5650f8816830): Non uniform sampling or missing slices detected,  maximum nonuniformity:9.83278e-05\n",
      "\n",
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.2/itkImageSeriesReader.hxx, line 480\n",
      "ImageSeriesReader (0x5650f8816830): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.000625682\n",
      "\n",
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.2/itkImageSeriesReader.hxx, line 480\n",
      "ImageSeriesReader (0x5650f8816830): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.000389275\n",
      "\n",
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.2/itkImageSeriesReader.hxx, line 480\n",
      "ImageSeriesReader (0x5650f8816830): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.000389275\n",
      "\n",
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.2/itkImageSeriesReader.hxx, line 480\n",
      "ImageSeriesReader (0x5650f8816830): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.000774241\n",
      "\n",
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.2/itkImageSeriesReader.hxx, line 480\n",
      "ImageSeriesReader (0x5650f8816830): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.000681891\n",
      "\n",
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.2/itkImageSeriesReader.hxx, line 480\n",
      "ImageSeriesReader (0x5650f8816830): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.000820297\n",
      "\n",
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.2/itkImageSeriesReader.hxx, line 480\n",
      "ImageSeriesReader (0x5650f8816830): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.00083914\n",
      "\n",
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.2/itkImageSeriesReader.hxx, line 480\n",
      "ImageSeriesReader (0x5650f8816830): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.000814357\n",
      "\n",
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.2/itkImageSeriesReader.hxx, line 480\n",
      "ImageSeriesReader (0x5650f8816830): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.000100322\n",
      "\n",
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.2/itkImageSeriesReader.hxx, line 480\n",
      "ImageSeriesReader (0x5650f8816830): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.000879059\n",
      "\n",
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.2/itkImageSeriesReader.hxx, line 480\n",
      "ImageSeriesReader (0x5650f8816830): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.000553183\n",
      "\n",
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.2/itkImageSeriesReader.hxx, line 480\n",
      "ImageSeriesReader (0x5650f8816830): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.0002\n",
      "\n",
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.2/itkImageSeriesReader.hxx, line 480\n",
      "ImageSeriesReader (0x5650f8816830): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.0002\n",
      "\n",
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.2/itkImageSeriesReader.hxx, line 480\n",
      "ImageSeriesReader (0x5650f8816830): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.000858202\n",
      "\n",
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.2/itkImageSeriesReader.hxx, line 480\n",
      "ImageSeriesReader (0x5650f8816830): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.00099726\n",
      "\n",
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.2/itkImageSeriesReader.hxx, line 480\n",
      "ImageSeriesReader (0x5650f8816830): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.000555953\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1642689/2130051900.py\u001b[0m in \u001b[0;36mtrain_mri_type\u001b[0;34m(df, df_test, mri_type, skf)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"models/fold_{i}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         history = trainer.fit(\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1642689/3080179659.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, train_loader, valid_loader, save_path, patience)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"EPOCH: {}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1642689/3080179659.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, train_loader)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0msum_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/pytorch/lib/python3.8/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/pytorch/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/pytorch/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/pytorch/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/pytorch/lib/python3.8/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "oof_train = []\n",
    "oof_test = []\n",
    "modelfiles = []\n",
    "\n",
    "for mri_type in mri_types:\n",
    "    trn, tst, modelfile = train_mri_type(df, df_test, mri_type, rkf)\n",
    "    oof_train.append(trn)\n",
    "    oof_test.append(tst)\n",
    "    modelfiles.append(modelfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"oof_train.npy\", oof_train)\n",
    "np.save(\"oof_test.npy\", oof_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f53038aa280>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/christian/miniconda/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/christian/miniconda/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1301, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/christian/miniconda/envs/pytorch/lib/python3.8/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/home/christian/miniconda/envs/pytorch/lib/python3.8/multiprocessing/popen_fork.py\", line 44, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/home/christian/miniconda/envs/pytorch/lib/python3.8/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/christian/miniconda/envs/pytorch/lib/python3.8/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis2: axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1642689/814430352.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moof_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moof_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mswapaxes\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/pytorch/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mswapaxes\u001b[0;34m(a, axis1, axis2)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m     \"\"\"\n\u001b[0;32m--> 595\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'swapaxes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/pytorch/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis2: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "x_train = np.swapaxes(np.array(oof_train), 0, 1)\n",
    "x_test = np.swapaxes(np.array(oof_test), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df), len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(f\"{data_directory}/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, mri_type in enumerate(mri_types):\n",
    "    df[f\"level0_{mri_type}_preds\"] = x_train[:, i]\n",
    "    df_test[f\"level0_{mri_type}_preds\"] = x_test[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"MGMT_value\"].values\n",
    "X = df.drop([\"MGMT_value\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'learning_rate': [0.01, 0.005, 0.001],\n",
    "    'n_estimators': [5000, 10000], # 1000, 20000\n",
    "    'min_child_weight': [1, 5, 10, 20],\n",
    "    'gamma': [2, 3, 5],\n",
    "    'subsample': [1.0], # 0.6, 0.8, \n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 5\n",
    "param_comb = 20\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=1001)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    gbc,\n",
    "    param_distributions=params,\n",
    "    n_iter=param_comb,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=8,\n",
    "    cv=skf.split(X, y),\n",
    "    verbose=10,\n",
    "    random_state=1001,\n",
    ")\n",
    "\n",
    "random_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n All results:')\n",
    "print(random_search.cv_results_)\n",
    "print('\\n Best estimator:')\n",
    "print(random_search.best_estimator_)\n",
    "print('\\n Best normalized gini score for %d-fold search with %d parameter combinations:' % (folds, param_comb))\n",
    "print(random_search.best_score_ * 2 - 1)\n",
    "print('\\n Best hyperparameters:')\n",
    "print(random_search.best_params_)\n",
    "results = pd.DataFrame(random_search.cv_results_)\n",
    "results.to_csv('xgb-random-grid-search-results-01.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[results[\"rank_test_score\"] < 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[results[\"rank_test_score\"] < 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df_test.copy()\n",
    "x_test = x_test.drop([\"MGMT_value\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = random_search.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = test_preds[:,1]\n",
    "test_preds[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T17:04:47.358254Z",
     "iopub.status.busy": "2021-09-09T17:04:47.357907Z",
     "iopub.status.idle": "2021-09-09T17:05:19.089039Z",
     "shell.execute_reply": "2021-09-09T17:05:19.086785Z",
     "shell.execute_reply.started": "2021-09-09T17:04:47.358222Z"
    }
   },
   "outputs": [],
   "source": [
    "# auc = roc_auc_score(y_valid, val_preds)\n",
    "# print(f\"Validation ensemble AUC: {auc:.4f}\")\n",
    "sns.displot(test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-09T16:58:32.413937Z",
     "iopub.status.idle": "2021-09-09T16:58:32.414306Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv(f\"{data_directory}/sample_submission.csv\")\n",
    "submission[\"MGMT_value\"] = test_preds\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
