{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-09-26T00:53:30.899515Z",
     "iopub.status.busy": "2021-09-26T00:53:30.899184Z",
     "iopub.status.idle": "2021-09-26T00:53:36.562093Z",
     "shell.execute_reply": "2021-09-26T00:53:36.560954Z",
     "shell.execute_reply.started": "2021-09-26T00:53:30.899441Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "import nibabel as nib\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import tensorflow_hub as tfhub\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "\n",
    "TYPES = [\"FLAIR\", \"T1w\", \"T2w\", \"T1wCE\"]\n",
    "WHITE_THRESHOLD = 10 # out of 255\n",
    "EXCLUDE = [109, 123, 709]\n",
    "IMAGE_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"/kaggle/input/rsna-miccai-brain-tumor-radiogenomic-classification\"):\n",
    "    # data_directory = \"/kaggle/input/rsna-miccai-brain-tumor-radiogenomic-classification\"\n",
    "    data_directory = \"/kaggle/input/rsna-preprocessed\"\n",
    "    pretrained_weights_path = \\\n",
    "        \"/kaggle/input/efficientnetv2-tfhub-weight-files/tfhub_models/efficientnetv2-m-21k/feature_vector\"\n",
    "else:\n",
    "    # data_directory = \"rsna-miccai-brain-tumor-radiogenomic-classification\"\n",
    "    data_directory = \"rsna-preprocessed\"\n",
    "    pretrained_weights_path = \\\n",
    "        \"efficientnetv2-tfhub-weight-files/tfhub_models/efficientnetv2-m-21k/feature_vector\"\n",
    "\n",
    "experiment_folder = \"experiments/efficientnet2d_preprocessed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f\"{data_directory}/train_labels.csv\")\n",
    "test_df = pd.read_csv(f\"{data_directory}/sample_submission.csv\")\n",
    "train_df = train_df[~train_df.BraTS21ID.isin(EXCLUDE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T00:53:36.564124Z",
     "iopub.status.busy": "2021-09-26T00:53:36.563770Z",
     "iopub.status.idle": "2021-09-26T00:53:36.578666Z",
     "shell.execute_reply": "2021-09-26T00:53:36.577858Z",
     "shell.execute_reply.started": "2021-09-26T00:53:36.564088Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_dicom(path, size = 224):\n",
    "    ''' \n",
    "    Reads a DICOM image, standardizes so that the pixel values are between 0 and 1, then rescales to 0 and 255\n",
    "    \n",
    "    Note super sure if this kind of scaling is appropriate, but everyone seems to do it. \n",
    "    '''\n",
    "    dicom = pydicom.read_file(path)\n",
    "    data = dicom.pixel_array\n",
    "    if np.max(data) != 0:\n",
    "        data = data / np.max(data)\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "    return cv2.resize(data, (size, size))\n",
    "\n",
    "def get_all_image_paths(brats21id, image_type, folder='train'): \n",
    "    '''\n",
    "    Returns an arry of all the images of a particular type for a particular patient ID\n",
    "    '''\n",
    "    assert(image_type in TYPES)\n",
    "    \n",
    "    patient_path = os.path.join(\n",
    "        f\"{data_directory}/%s/\" % folder, \n",
    "        str(brats21id).zfill(5),\n",
    "    )\n",
    "\n",
    "    paths = sorted(\n",
    "        glob.glob(os.path.join(patient_path, image_type, \"*\")), \n",
    "        key=lambda x: int(x[:-4].split(\"-\")[-1]),\n",
    "    )\n",
    "    num_images = len(paths)\n",
    "    \n",
    "    start = int(num_images * 0.25)\n",
    "    end = int(num_images * 0.75)\n",
    "\n",
    "    interval = 3\n",
    "    \n",
    "    if num_images < 10: \n",
    "        interval = 1\n",
    "    \n",
    "    return np.array(paths[start:end:interval])\n",
    "\n",
    "def get_all_images(brats21id, image_type, folder='train', size=225):\n",
    "    return [load_dicom(path, size) for path in get_all_image_paths(brats21id, image_type, folder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nib(path, size = 224):\n",
    "    data = nib.load(path).get_fdata()\n",
    "\n",
    "    if np.max(data) != 0:\n",
    "        data = data / np.max(data)\n",
    "        \n",
    "    data = (data * 255).astype(np.uint8)\n",
    "    \n",
    "    num_images = data.shape[-1]\n",
    "    \n",
    "    start = int(num_images * 0.25)\n",
    "    end = int(num_images * 0.75)\n",
    "    interval = 3\n",
    "    \n",
    "    if num_images < 10: \n",
    "        interval = 1\n",
    "\n",
    "    data = data[:, :, start:end:interval]\n",
    "    data = data.swapaxes(2, 0)\n",
    "    resized = []\n",
    "    for image in data:\n",
    "        resized.append(cv2.resize(image, (size, size)))\n",
    "    data = np.array(resized)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_all_preprocessed_image_paths(brats21id, image_type, folder='train'): \n",
    "    '''\n",
    "    Returns an arry of all the images of a particular type for a particular patient ID\n",
    "    '''\n",
    "    assert(image_type in TYPES)\n",
    "    \n",
    "    patient_path = os.path.join(\n",
    "        f\"{data_directory}/%s/\" % folder, \n",
    "        str(brats21id).zfill(5),\n",
    "    )\n",
    "\n",
    "    paths = sorted(\n",
    "        glob.glob(os.path.join(patient_path, image_type, \"*\")), \n",
    "    )\n",
    "    \n",
    "    return np.array(paths)\n",
    "\n",
    "def get_all_preprocessed_images(brats21id, image_type, folder='train', size=225):\n",
    "    path = get_all_preprocessed_image_paths(brats21id, image_type, folder)[0]\n",
    "    data = load_nib(path, size)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T00:53:36.586848Z",
     "iopub.status.busy": "2021-09-26T00:53:36.584336Z",
     "iopub.status.idle": "2021-09-26T00:53:36.601064Z",
     "shell.execute_reply": "2021-09-26T00:53:36.599987Z",
     "shell.execute_reply.started": "2021-09-26T00:53:36.586761Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_all_data_for_train(image_type):\n",
    "    global train_df\n",
    "    X = []\n",
    "    y = []\n",
    "    train_ids = []\n",
    "    for i in tqdm(train_df.index):\n",
    "        x = train_df.loc[i]\n",
    "        images = get_all_preprocessed_images(int(x['BraTS21ID']), image_type, 'train', IMAGE_SIZE)\n",
    "        label = x['MGMT_value']\n",
    "\n",
    "        X.append(images)\n",
    "        y += [label] * len(images)\n",
    "        train_ids += [int(x['BraTS21ID'])] * len(images)\n",
    "        \n",
    "    X = np.concatenate(X)\n",
    "    return X, np.array(y), np.array(train_ids)\n",
    "\n",
    "def get_all_data_for_test(image_type):\n",
    "    global test_df\n",
    "    X = []\n",
    "    test_ids = []\n",
    "    for i in tqdm(test_df.index):\n",
    "        x = test_df.loc[i]\n",
    "        images = get_all_preprocessed_images(int(x['BraTS21ID']), image_type, 'test', IMAGE_SIZE)\n",
    "        X.append(images)\n",
    "        test_ids += [int(x['BraTS21ID'])] * len(images)\n",
    "\n",
    "    X = np.concatenate(X)\n",
    "    return X, np.array(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-26T00:53:36.608918Z",
     "iopub.status.busy": "2021-09-26T00:53:36.606262Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c6bd20d76ca43318515ee2d24b8d851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/582 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d511b3805aac4d69bf535b576653bf85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/87 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((17826, 256, 256), (17826,), (17826,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y, trainidt = get_all_data_for_train('T1wCE')\n",
    "X_test, testidt = get_all_data_for_test('T1wCE')\n",
    "X.shape, y.shape, trainidt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X[:128]\n",
    "# y = y[:128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17826, 256, 256), (17826,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-27 19:55:58.385467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-27 19:55:58.395945: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-27 19:55:58.396463: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-27 19:55:58.397485: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-27 19:55:58.431606: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-27 19:55:58.432618: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-27 19:55:58.433337: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-27 19:55:58.781564: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-27 19:55:58.782062: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-27 19:55:58.782504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-27 19:55:58.782946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6311 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:0a:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(X):\n",
    "    inpt = keras.Input(shape=X.shape[1:])\n",
    "    inp = tf.keras.layers.Concatenate()([inpt, inpt, inpt])  \n",
    "\n",
    "    h = keras.layers.experimental.preprocessing.Rescaling(1./255)(inp)\n",
    "    # h = data_augmentation(h)\n",
    "\n",
    "    # convolutional layer!\n",
    "    # h = keras.layers.Conv2D(3, kernel_size=(3, 3),activation=\"relu\", name=\"Conv_1\", padding=\"same\")(h) \n",
    "    # h = tf.keras.layers.BatchNormalization(axis=-1)(h)\n",
    "    h = tfhub.KerasLayer(pretrained_weights_path, trainable=True)(h)\n",
    "\n",
    "    # h = keras.layers.Flatten()(h) \n",
    "    # h = global_average_layer(h)\n",
    "    h = keras.layers.Dropout(0.2)(h)\n",
    "    h = keras.layers.Dense(128, activation='relu')(h)   \n",
    "\n",
    "    output = keras.layers.Dense(2, activation=\"sigmoid\")(h)\n",
    "\n",
    "    model = keras.Model(inpt, output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(12)\n",
    "tf.random.set_seed(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X_valid):\n",
    "    y_pred = model.predict(X_valid)\n",
    "    predictions = np.argmax(y_pred, axis=1)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X_valid, trainidt_valid):\n",
    "    y_pred = model.predict(X_valid)\n",
    "    pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    result=pd.DataFrame(trainidt_valid)\n",
    "    result[1]=pred\n",
    "\n",
    "    result.columns=['BraTS21ID','MGMT_value']\n",
    "    result = result.groupby('BraTS21ID',as_index=False).mean()\n",
    "\n",
    "    result = result.merge(train_df, on='BraTS21ID')\n",
    "    print(f\"roc auc: {roc_auc_score(result.MGMT_value_y, result.MGMT_value_x,)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission(predictions, index): \n",
    "    sample = pd.read_csv(f'{data_directory}/sample_submission.csv')\n",
    "\n",
    "    submission = pd.DataFrame(testidt)\n",
    "    submission[1] = predictions\n",
    "\n",
    "    submission.columns = ['BraTS21ID','MGMT_value']\n",
    "    submission = submission.groupby('BraTS21ID', as_index=False).mean()\n",
    "    submission['BraTS21ID'] = submission['BraTS21ID']\n",
    "    submission['MGMT_value'] = submission['MGMT_value'].apply(lambda x:round(x*10)/10)\n",
    "\n",
    "    os.makedirs(f'{experiment_folder}/fold_{index}', exist_ok=True)\n",
    "    submission.to_csv(f'{experiment_folder}/fold_{index}/submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `skf.split` not found.\n"
     ]
    }
   ],
   "source": [
    "skf.split??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-27 19:56:18.322366: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-27 19:56:44.397438: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8204\n",
      "2021-09-27 19:56:45.420275: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.40GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-09-27 19:56:45.447411: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.42GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-09-27 19:56:45.550763: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.39GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-09-27 19:56:45.554365: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.40GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-09-27 19:56:45.591201: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.39GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-09-27 19:56:45.594669: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.42GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3565/3565 [==============================] - 684s 184ms/step - loss: 0.7126 - auc: 0.5383 - val_loss: 0.6764 - val_auc: 0.5685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-27 20:07:42.304841: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.40GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-09-27 20:07:42.330507: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.41GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "3565/3565 [==============================] - 644s 181ms/step - loss: 0.6758 - auc: 0.5753 - val_loss: 0.6383 - val_auc: 0.6713\n",
      "Epoch 3/10\n",
      "3565/3565 [==============================] - 633s 178ms/step - loss: 0.6454 - auc: 0.6448 - val_loss: 0.6532 - val_auc: 0.6846\n",
      "Epoch 4/10\n",
      "3565/3565 [==============================] - 638s 179ms/step - loss: 0.5603 - auc: 0.7671 - val_loss: 0.5321 - val_auc: 0.8046\n",
      "Epoch 5/10\n",
      "3565/3565 [==============================] - 632s 177ms/step - loss: 0.3934 - auc: 0.8977 - val_loss: 0.4437 - val_auc: 0.8769\n",
      "Epoch 6/10\n",
      "3565/3565 [==============================] - 649s 182ms/step - loss: 0.2419 - auc: 0.9617 - val_loss: 0.4254 - val_auc: 0.9031\n",
      "Epoch 7/10\n",
      "3565/3565 [==============================] - 640s 179ms/step - loss: 0.1540 - auc: 0.9845 - val_loss: 0.6370 - val_auc: 0.8688\n",
      "Epoch 8/10\n",
      "3565/3565 [==============================] - 617s 173ms/step - loss: 0.1279 - auc: 0.9893 - val_loss: 0.4918 - val_auc: 0.9006\n",
      "Epoch 9/10\n",
      "3565/3565 [==============================] - 618s 173ms/step - loss: 0.0591 - auc: 0.9974 - val_loss: 0.5093 - val_auc: 0.9298\n",
      "Epoch 10/10\n",
      "3565/3565 [==============================] - 619s 174ms/step - loss: 0.0440 - auc: 0.9986 - val_loss: 0.5259 - val_auc: 0.9258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-27 21:42:55.257758: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.43GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-09-27 21:42:55.298004: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.61GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc auc: 0.6201040026716282\n",
      "Epoch 1/10\n",
      "3566/3566 [==============================] - 686s 186ms/step - loss: 0.7092 - auc_1: 0.5405 - val_loss: 0.6702 - val_auc_1: 0.5735\n",
      "Epoch 2/10\n",
      "3566/3566 [==============================] - 660s 185ms/step - loss: 0.6650 - auc_1: 0.5781 - val_loss: 0.6513 - val_auc_1: 0.6166\n",
      "Epoch 3/10\n",
      "3566/3566 [==============================] - 661s 185ms/step - loss: 0.6258 - auc_1: 0.6353 - val_loss: 0.6034 - val_auc_1: 0.6618\n",
      "Epoch 4/10\n",
      "3566/3566 [==============================] - 660s 185ms/step - loss: 0.5104 - auc_1: 0.7715 - val_loss: 0.4934 - val_auc_1: 0.8295\n",
      "Epoch 5/10\n",
      "3566/3566 [==============================] - 661s 185ms/step - loss: 0.3425 - auc_1: 0.9127 - val_loss: 0.4184 - val_auc_1: 0.8902\n",
      "Epoch 6/10\n",
      "3566/3566 [==============================] - 660s 185ms/step - loss: 0.2140 - auc_1: 0.9659 - val_loss: 0.4451 - val_auc_1: 0.9099\n",
      "Epoch 7/10\n",
      "3566/3566 [==============================] - 659s 185ms/step - loss: 0.1563 - auc_1: 0.9828 - val_loss: 0.4080 - val_auc_1: 0.9092\n",
      "Epoch 8/10\n",
      "3566/3566 [==============================] - 664s 186ms/step - loss: 0.1209 - auc_1: 0.9882 - val_loss: 0.4855 - val_auc_1: 0.9044\n",
      "Epoch 9/10\n",
      "3566/3566 [==============================] - 692s 194ms/step - loss: 0.1074 - auc_1: 0.9898 - val_loss: 0.4221 - val_auc_1: 0.9055\n",
      "Epoch 10/10\n",
      "3566/3566 [==============================] - 694s 195ms/step - loss: 0.0463 - auc_1: 0.9978 - val_loss: 0.5095 - val_auc_1: 0.9303\n",
      "roc auc: 0.6373236079328757\n",
      "Epoch 1/10\n",
      "3566/3566 [==============================] - 717s 194ms/step - loss: 0.7067 - auc_2: 0.5356 - val_loss: 0.6538 - val_auc_2: 0.6352\n",
      "Epoch 2/10\n",
      "3566/3566 [==============================] - 692s 194ms/step - loss: 0.6741 - auc_2: 0.5775 - val_loss: 0.6620 - val_auc_2: 0.6553\n",
      "Epoch 3/10\n",
      "3566/3566 [==============================] - 689s 193ms/step - loss: 0.6431 - auc_2: 0.6298 - val_loss: 0.6258 - val_auc_2: 0.6594\n",
      "Epoch 4/10\n",
      "3566/3566 [==============================] - 690s 194ms/step - loss: 0.5625 - auc_2: 0.7493 - val_loss: 0.5210 - val_auc_2: 0.8122\n",
      "Epoch 5/10\n",
      "3566/3566 [==============================] - 689s 193ms/step - loss: 0.3926 - auc_2: 0.8960 - val_loss: 0.4640 - val_auc_2: 0.8651\n",
      "Epoch 6/10\n",
      "3566/3566 [==============================] - 676s 189ms/step - loss: 0.2379 - auc_2: 0.9616 - val_loss: 0.4322 - val_auc_2: 0.9010\n",
      "Epoch 7/10\n",
      "3566/3566 [==============================] - 661s 185ms/step - loss: 0.1617 - auc_2: 0.9817 - val_loss: 0.5091 - val_auc_2: 0.9051\n",
      "Epoch 8/10\n",
      "3566/3566 [==============================] - 660s 185ms/step - loss: 0.1309 - auc_2: 0.9878 - val_loss: 0.5158 - val_auc_2: 0.9017\n",
      "Epoch 9/10\n",
      "3566/3566 [==============================] - 662s 186ms/step - loss: 0.0550 - auc_2: 0.9977 - val_loss: 0.5737 - val_auc_2: 0.9189\n",
      "Epoch 10/10\n",
      "3566/3566 [==============================] - 675s 189ms/step - loss: 0.0430 - auc_2: 0.9985 - val_loss: 0.5946 - val_auc_2: 0.9221\n",
      "roc auc: 0.6447092218882687\n",
      "Epoch 1/10\n",
      "3566/3566 [==============================] - 683s 185ms/step - loss: 0.7057 - auc_3: 0.5548 - val_loss: 0.6804 - val_auc_3: 0.5646\n",
      "Epoch 2/10\n",
      "3566/3566 [==============================] - 659s 185ms/step - loss: 0.6678 - auc_3: 0.5980 - val_loss: 0.6770 - val_auc_3: 0.6265\n",
      "Epoch 3/10\n",
      "3566/3566 [==============================] - 658s 184ms/step - loss: 0.6378 - auc_3: 0.6493 - val_loss: 0.6126 - val_auc_3: 0.6585\n",
      "Epoch 4/10\n",
      "3566/3566 [==============================] - 657s 184ms/step - loss: 0.5534 - auc_3: 0.7455 - val_loss: 0.5532 - val_auc_3: 0.7613\n",
      "Epoch 5/10\n",
      "3566/3566 [==============================] - 658s 185ms/step - loss: 0.3925 - auc_3: 0.8750 - val_loss: 0.4679 - val_auc_3: 0.8581\n",
      "Epoch 6/10\n",
      "3566/3566 [==============================] - 656s 184ms/step - loss: 0.2465 - auc_3: 0.9523 - val_loss: 0.4465 - val_auc_3: 0.8957\n",
      "Epoch 7/10\n",
      "3566/3566 [==============================] - 657s 184ms/step - loss: 0.1743 - auc_3: 0.9738 - val_loss: 0.4199 - val_auc_3: 0.9020\n",
      "Epoch 8/10\n",
      "3566/3566 [==============================] - 660s 185ms/step - loss: 0.1315 - auc_3: 0.9860 - val_loss: 0.5045 - val_auc_3: 0.8988\n",
      "Epoch 9/10\n",
      "3566/3566 [==============================] - 657s 184ms/step - loss: 0.1077 - auc_3: 0.9898 - val_loss: 0.4044 - val_auc_3: 0.9093\n",
      "Epoch 10/10\n",
      "3566/3566 [==============================] - 659s 185ms/step - loss: 0.0963 - auc_3: 0.9907 - val_loss: 0.5441 - val_auc_3: 0.8880\n",
      "roc auc: 0.6063453159041394\n",
      "Epoch 1/10\n",
      "3566/3566 [==============================] - 684s 185ms/step - loss: 0.7043 - auc_4: 0.5505 - val_loss: 0.6680 - val_auc_4: 0.6163\n",
      "Epoch 2/10\n",
      "3566/3566 [==============================] - 659s 185ms/step - loss: 0.6726 - auc_4: 0.5844 - val_loss: 0.6614 - val_auc_4: 0.5852\n",
      "Epoch 3/10\n",
      "3566/3566 [==============================] - 659s 185ms/step - loss: 0.6525 - auc_4: 0.5981 - val_loss: 0.6212 - val_auc_4: 0.6030\n",
      "Epoch 4/10\n",
      "3566/3566 [==============================] - 657s 184ms/step - loss: 0.5810 - auc_4: 0.6810 - val_loss: 0.5670 - val_auc_4: 0.6860\n",
      "Epoch 5/10\n",
      "3566/3566 [==============================] - 657s 184ms/step - loss: 0.4232 - auc_4: 0.8558 - val_loss: 0.4651 - val_auc_4: 0.8564\n",
      "Epoch 6/10\n",
      "3566/3566 [==============================] - 658s 184ms/step - loss: 0.2616 - auc_4: 0.9469 - val_loss: 0.4218 - val_auc_4: 0.8847\n",
      "Epoch 7/10\n",
      "3566/3566 [==============================] - 658s 184ms/step - loss: 0.1701 - auc_4: 0.9746 - val_loss: 0.4645 - val_auc_4: 0.8882\n",
      "Epoch 8/10\n",
      "3566/3566 [==============================] - 658s 184ms/step - loss: 0.1240 - auc_4: 0.9873 - val_loss: 0.5083 - val_auc_4: 0.9089\n",
      "Epoch 9/10\n",
      "3566/3566 [==============================] - 659s 185ms/step - loss: 0.0569 - auc_4: 0.9971 - val_loss: 0.4930 - val_auc_4: 0.9250\n",
      "Epoch 10/10\n",
      "3566/3566 [==============================] - 657s 184ms/step - loss: 0.0400 - auc_4: 0.9985 - val_loss: 0.6969 - val_auc_4: 0.9157\n",
      "roc auc: 0.9812866752540432\n"
     ]
    }
   ],
   "source": [
    "for i, (train_index, val_index) in enumerate(skf.split(X, y)):\n",
    "    X_train = X[train_index]\n",
    "    X_valid = X[val_index]\n",
    "    y_train = y[train_index]\n",
    "    y_valid = y[val_index]\n",
    "    trainidt_train = trainidt[train_index]\n",
    "    trainidt_valid = trainidt[val_index]\n",
    "\n",
    "    X_train = tf.expand_dims(X_train, axis=-1)\n",
    "    X_valid = tf.expand_dims(X_valid, axis=-1)\n",
    "\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_valid = to_categorical(y_valid)\n",
    "\n",
    "    checkpoint_filepath = f'{experiment_folder}/fold_{i}/best_model.h5'\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=False,\n",
    "        monitor='val_loss',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        save_freq='epoch'\n",
    "    )\n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=2,\n",
    "        min_lr=0.00001\n",
    "    )\n",
    "    # lr_schedule = tf.optimizers.schedules.ExponentialDecay(1e-4, 100, 0.9)\n",
    "    # wd_schedule = tf.optimizers.schedules.ExponentialDecay(5e-5, 100, 0.9)\n",
    "    # opt = tfa.optimizers.AdamW(learning_rate=lr_schedule, weight_decay=lambda : None)\n",
    "    # opt.weight_decay = lambda : wd_schedule(opt.iterations)\n",
    "\n",
    "    model = build_model(X_train)\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate = 0.0001),\n",
    "        metrics=[tf.keras.metrics.AUC()]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        x=X_train,\n",
    "        y=y_train,\n",
    "        epochs=10,\n",
    "        batch_size=4,\n",
    "        callbacks=[model_checkpoint_callback,reduce_lr],\n",
    "        validation_data=(X_valid, y_valid)\n",
    "    )\n",
    "    best_model = tf.keras.models.load_model(filepath=checkpoint_filepath,custom_objects={'KerasLayer': tfhub.KerasLayer})\n",
    "    \n",
    "    val_preds = evaluate(best_model, X_valid, trainidt_valid)\n",
    "    test_preds = predict(best_model, X_test)\n",
    "    submission = generate_submission(test_preds, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = \"/home/christian/Documents/projects/brain-tumor-classification/experiments/efficientnet2d_preprocessed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_0\n",
      "fold_4\n",
      "fold_1\n",
      "fold_2\n",
      "fold_3\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "for fold_dir in os.listdir(path):\n",
    "    print(fold_dir)\n",
    "    sub = pd.read_csv(os.path.join(path, fold_dir, \"submission.csv\"))\n",
    "    preds.append(sub[\"MGMT_value\"])\n",
    "preds = np.mean(preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8 , 0.72, 0.68, 0.7 , 0.9 , 0.78, 0.62, 0.76, 0.74, 0.98, 0.62,\n",
       "       0.06, 0.3 , 0.26, 0.64, 0.62, 0.28, 0.26, 0.08, 0.16, 0.12, 0.54,\n",
       "       0.28, 0.38, 0.06, 0.26, 0.24, 0.24, 0.12, 0.36, 0.34, 0.64, 0.22,\n",
       "       0.18, 0.08, 0.08, 0.06, 0.24, 0.34, 0.18, 0.68, 0.16, 0.82, 0.16,\n",
       "       0.18, 0.34, 0.58, 0.58, 0.66, 0.8 , 0.58, 0.5 , 0.9 , 0.78, 0.8 ,\n",
       "       0.72, 0.68, 0.82, 0.92, 0.54, 0.22, 0.76, 0.62, 0.64, 0.64, 0.78,\n",
       "       0.62, 0.82, 0.7 , 0.8 , 0.58, 0.84, 0.92, 0.78, 0.48, 0.86, 0.7 ,\n",
       "       0.76, 0.74, 0.6 , 0.82, 0.72, 0.86, 0.82, 0.22, 0.46, 0.5 ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[\"MGMT_value\"] = preds\n",
    "sub.to_csv(os.path.join(path, \"submission.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
