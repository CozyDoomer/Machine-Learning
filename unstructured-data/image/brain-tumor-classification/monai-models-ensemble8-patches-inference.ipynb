{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use stacked images (3D) and Densenet121 3D model\n",
    "\n",
    "Acknowledgements:\n",
    "\n",
    "- https://www.kaggle.com/rluethy/efficientnet3d-with-one-mri-type\n",
    "- https://www.kaggle.com/davidbroberts/determining-dicom-image-order\n",
    "- https://www.kaggle.com/ihelon/brain-tumor-eda-with-animations-and-modeling\n",
    "- https://www.kaggle.com/furcifer/torch-efficientnet3d-for-mri-no-train\n",
    "- https://github.com/shijianjian/EfficientNet-PyTorch-3D\n",
    "\n",
    "This notebook is based on the implementation of Densenet121 3D available here:\n",
    "https://www.kaggle.com/mikecho/monai-v060-deep-learning-in-healthcare-imaging\n",
    "\n",
    "It builds 4 models with only one MRI type, then ensembles all of them computing average probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T16:39:28.897999Z",
     "iopub.status.busy": "2021-09-09T16:39:28.897707Z",
     "iopub.status.idle": "2021-09-09T16:39:31.381066Z",
     "shell.execute_reply": "2021-09-09T16:39:31.380198Z",
     "shell.execute_reply.started": "2021-09-09T16:39:28.897933Z"
    },
    "papermill": {
     "duration": 1.048295,
     "end_time": "2021-07-14T20:26:46.309722",
     "exception": false,
     "start_time": "2021-07-14T20:26:45.261427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import re\n",
    "import collections\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import cv2\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data as torch_data\n",
    "from sklearn import model_selection as sk_model_selection\n",
    "from torch.nn import functional as torch_functional\n",
    "\n",
    "import torchio as tio\n",
    "import nibabel as nib\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"/kaggle/input/rsna-miccai-brain-tumor-radiogenomic-classification\"):\n",
    "    data_directory = \"/kaggle/input/rsna-miccai-brain-tumor-radiogenomic-classification\"\n",
    "    input_monaipath = \"/kaggle/input/monai-v060-deep-learning-in-healthcare-imaging/\"\n",
    "    landmarks_directory = \"/kaggle/input/rsna-landmarks\"\n",
    "else:\n",
    "    data_directory = \"rsna-miccai-brain-tumor-radiogenomic-classification\"\n",
    "    input_monaipath = \"MONAI\"\n",
    "    landmarks_directory = \"rsna-landmarks\"\n",
    "\n",
    "processed_data_dir = 'rsna-preprocessed'\n",
    "experiment_folder = \"experiments/patch_seresnext50_3fold_stacking\"\n",
    "model_paths = f\"{experiment_folder}/models\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(experiment_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T16:39:35.258348Z",
     "iopub.status.busy": "2021-09-09T16:39:35.256703Z",
     "iopub.status.idle": "2021-09-09T16:39:37.741004Z",
     "shell.execute_reply": "2021-09-09T16:39:37.740092Z",
     "shell.execute_reply.started": "2021-09-09T16:39:35.258304Z"
    },
    "lines_to_end_of_cell_marker": 2,
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 0.05565,
     "end_time": "2021-07-14T20:26:46.486521",
     "exception": false,
     "start_time": "2021-07-14T20:26:46.430871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mri_types = ['FLAIR', 'T1w', 'T1wCE', 'T2w']\n",
    "\n",
    "SIZE = 512\n",
    "NUM_IMAGES = 32\n",
    "BATCH_SIZE = 4\n",
    "PATCH_SIZE = (128, 128, 96)\n",
    "\n",
    "# EPOCHS = 10\n",
    "# MIN_LR = 1e-6\n",
    "# LR = 0.001\n",
    "EPOCHS = 10\n",
    "LR = 1e-4\n",
    "\n",
    "NUM_FOLDS = 3\n",
    "SEED = 42\n",
    "\n",
    "sys.path.append(input_monaipath)\n",
    "\n",
    "# worked well ?\n",
    "# from monai.networks.nets.densenet import DenseNet121\n",
    "# failed\n",
    "# from monai.networks.nets.vit import ViT\n",
    "from monai.networks.nets.senet import SEResNext50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOTAL_EPOCHS = EPOCHS * len(mri_types) * NUM_FOLDS\n",
    "TOTAL_EPOCHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_transforms = (\n",
    "    tio.ToCanonical(),\n",
    "    tio.Resample(1, image_interpolation='bspline'),\n",
    "    tio.Resample('T1w', image_interpolation='nearest'),\n",
    ")\n",
    "preprocess = tio.Compose(preprocessing_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = tio.datasets.RSNAMICCAI(data_directory, train=True, transform=preprocess)\n",
    "test_set = tio.datasets.RSNAMICCAI(data_directory, train=False, transform=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(dataset, out_dir, parallel=True):\n",
    "    import shutil\n",
    "    import multiprocessing as mp\n",
    "    from pathlib import Path\n",
    "    from tqdm.notebook import tqdm\n",
    "    out_dir = Path(out_dir)\n",
    "    labels_name = 'train_labels.csv'\n",
    "    out_dir.mkdir(exist_ok=True, parents=True)\n",
    "    shutil.copy(dataset.root_dir / labels_name, out_dir / labels_name)\n",
    "    subjects_dir = out_dir / ('train' if dataset.train else 'test')\n",
    "    if parallel:\n",
    "        loader = torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            num_workers=mp.cpu_count(),\n",
    "            collate_fn=lambda x: x[0],\n",
    "        )\n",
    "        iterable = loader\n",
    "    else:\n",
    "        iterable = dataset\n",
    "    for subject in tqdm(iterable):\n",
    "        subject_dir = subjects_dir / subject.BraTS21ID\n",
    "        for name, image in tqdm(subject.get_images_dict().items(), leave=False):\n",
    "            image_dir = subject_dir / name\n",
    "            image_dir.mkdir(exist_ok=True, parents=True)\n",
    "            image_path = image_dir / f'{name}.nii.gz'\n",
    "            image.save(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 67 µs, sys: 0 ns, total: 67 µs\n",
      "Wall time: 57.5 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if not Path(processed_data_dir).is_dir():\n",
    "    preprocess_dataset(train_set, processed_data_dir)\n",
    "    preprocess_dataset(test_set, processed_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_dir = 'rsna-preprocessed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T16:39:37.74273Z",
     "iopub.status.busy": "2021-09-09T16:39:37.742391Z",
     "iopub.status.idle": "2021-09-09T16:39:38.474379Z",
     "shell.execute_reply": "2021-09-09T16:39:38.47359Z",
     "shell.execute_reply.started": "2021-09-09T16:39:37.742695Z"
    },
    "papermill": {
     "duration": 0.035761,
     "end_time": "2021-07-14T20:26:46.726756",
     "exception": false,
     "start_time": "2021-07-14T20:26:46.690995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 241, 241, 165)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_preprocessed_data_3d(scan_id, num_imgs=NUM_IMAGES, img_size=SIZE, mri_type=\"FLAIR\", split=\"train\"):\n",
    "    path = f\"{processed_data_dir}/{split}/{scan_id}/{mri_type}/{mri_type}.nii.gz\"\n",
    "    data = nib.load(path).get_fdata()\n",
    "    \n",
    "    # img_count = data.shape[-1]\n",
    "    # every_nth = img_count / num_imgs\n",
    "    # indexes = [min(int(round(i * every_nth)), img_count - 1) for i in range(0, num_imgs)]\n",
    "    # data = data[:, :, indexes]\n",
    "    # data = cv2.resize(data, (SIZE, SIZE))\n",
    "    \n",
    "    data = np.expand_dims(data, axis=0)\n",
    "    return data\n",
    "\n",
    "load_preprocessed_data_3d(\"00000\", mri_type=mri_types[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T16:39:38.477343Z",
     "iopub.status.busy": "2021-09-09T16:39:38.477088Z",
     "iopub.status.idle": "2021-09-09T16:39:38.539718Z",
     "shell.execute_reply": "2021-09-09T16:39:38.538874Z",
     "shell.execute_reply.started": "2021-09-09T16:39:38.477318Z"
    },
    "papermill": {
     "duration": 0.668331,
     "end_time": "2021-07-14T20:27:48.114522",
     "exception": false,
     "start_time": "2021-07-14T20:27:47.446191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove samples as described in https://www.kaggle.com/c/rsna-miccai-brain-tumor-radiogenomic-classification/discussion/262046"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T16:39:38.542555Z",
     "iopub.status.busy": "2021-09-09T16:39:38.54223Z",
     "iopub.status.idle": "2021-09-09T16:39:38.581634Z",
     "shell.execute_reply": "2021-09-09T16:39:38.580917Z",
     "shell.execute_reply.started": "2021-09-09T16:39:38.542521Z"
    },
    "papermill": {
     "duration": 0.633753,
     "end_time": "2021-07-14T20:27:49.350524",
     "exception": false,
     "start_time": "2021-07-14T20:27:48.716771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original shape (585, 2)\n",
      "new shape (582, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BraTS21ID</th>\n",
       "      <th>MGMT_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>1007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>1008</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>1009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>1010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>582 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     BraTS21ID  MGMT_value\n",
       "0            0           1\n",
       "1            2           1\n",
       "2            3           0\n",
       "3            5           1\n",
       "4            6           1\n",
       "..         ...         ...\n",
       "580       1005           1\n",
       "581       1007           1\n",
       "582       1008           1\n",
       "583       1009           0\n",
       "584       1010           0\n",
       "\n",
       "[582 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples_to_exclude = [109, 123, 709]\n",
    "\n",
    "df = pd.read_csv(f\"{data_directory}/train_labels.csv\")\n",
    "print(\"original shape\", df.shape)\n",
    "df = df[~df.BraTS21ID.isin(samples_to_exclude)]\n",
    "print(\"new shape\", df.shape)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.iloc[:16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch Dataset, augs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T16:39:38.597336Z",
     "iopub.status.busy": "2021-09-09T16:39:38.596904Z",
     "iopub.status.idle": "2021-09-09T16:39:38.608287Z",
     "shell.execute_reply": "2021-09-09T16:39:38.607285Z",
     "shell.execute_reply.started": "2021-09-09T16:39:38.597297Z"
    },
    "papermill": {
     "duration": 0.634322,
     "end_time": "2021-07-14T20:27:50.594701",
     "exception": false,
     "start_time": "2021-07-14T20:27:49.960379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dataset(torch_data.Dataset):\n",
    "    def __init__(self, paths, targets=None, mri_type=None, landmarks_dict=None, split=\"train\"):\n",
    "        self.paths = paths\n",
    "        self.targets = targets\n",
    "        self.mri_type = mri_type\n",
    "        self.landmarks_dict = landmarks_dict\n",
    "        self.split = split\n",
    "          \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        scan_id = self.paths[index]\n",
    "        if self.targets is None:\n",
    "            data = load_preprocessed_data_3d(str(scan_id).zfill(5), mri_type=self.mri_type[index], split=self.split) # augs = [\n",
    "            hs = np.array(PATCH_SIZE) // 2\n",
    "            x = int(np.random.uniform(hs[0], data.shape[1] - hs[0]))\n",
    "            y = int(np.random.uniform(hs[1], data.shape[2] - hs[1]))\n",
    "            z = int(np.random.uniform(hs[2], data.shape[3] - hs[2]))\n",
    "            data = data[:, x-hs[0]:x+hs[0], y-hs[1]:y+hs[1], z-hs[2]:z+hs[2]]\n",
    "        else:\n",
    "            data = load_preprocessed_data_3d(str(scan_id).zfill(5), mri_type=self.mri_type[index], split=\"train\")\n",
    "            augs = [\n",
    "                tio.RandomBlur(p=0.15),                    # blur 15% of times\n",
    "                tio.RandomNoise(p=0.15),                   # noise 15% of times\n",
    "                tio.RandomAffine(p=0.4),                   # affine transforms applied to 40% of images\n",
    "                tio.RandomBiasField(p=0.2),                # magnetic field inhomogeneity 20% of times\n",
    "                tio.OneOf({                                # either\n",
    "                    tio.RandomMotion(): 1,                 # random motion artifact\n",
    "                    tio.RandomSpike(): 2,                  # or spikes\n",
    "                    tio.RandomGhosting(): 2,               # or ghosts\n",
    "                }, p=0.2),                                 # applied to 20% of images\n",
    "            ]\n",
    "            transforms = tio.Compose(augs)\n",
    "            data = transforms(data)\n",
    "            \n",
    "            hs = np.array(PATCH_SIZE) // 2\n",
    "            x = int(np.random.uniform(hs[0], data.shape[1] - hs[0]))\n",
    "            y = int(np.random.uniform(hs[1], data.shape[2] - hs[1]))\n",
    "            z = int(np.random.uniform(hs[2], data.shape[3] - hs[2]))\n",
    "            data = data[:, x-hs[0]:x+hs[0], y-hs[1]:y+hs[1], z-hs[2]:z+hs[2]]\n",
    "\n",
    "            # import matplotlib.pyplot as plt\n",
    "            # fig, axs = plt.subplots(2)\n",
    "            # axs[0].imshow(data[0, :, :, 32], vmin=0, vmax=1)\n",
    "            # print(data.shape)\n",
    "            # data = transforms(data)\n",
    "            # print(data.shape)\n",
    "            # axs[1].imshow(data[0, :, :, 32], vmin=0, vmax=1)\n",
    "            # plt.show()\n",
    "            # print(\"============\")\n",
    "            \n",
    "        if self.targets is None:\n",
    "            return {\"X\": data, \"id\": scan_id}\n",
    "        else:\n",
    "            return {\"X\": data, \"y\": torch.tensor(self.targets[index], dtype=torch.float)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T16:39:38.610499Z",
     "iopub.status.busy": "2021-09-09T16:39:38.610156Z",
     "iopub.status.idle": "2021-09-09T16:39:38.618176Z",
     "shell.execute_reply": "2021-09-09T16:39:38.617273Z",
     "shell.execute_reply.started": "2021-09-09T16:39:38.610472Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    # model = DenseNet121(in_channels=1, out_channels=1, spatial_dims=3)\n",
    "    # model = ViT(\n",
    "    #     in_channels=1,\n",
    "    #     img_size=(SIZE, SIZE, NUM_IMAGES),\n",
    "    #     patch_size=PATCH_SIZE,\n",
    "    #     spatial_dims=3,\n",
    "    #     pos_embed='conv',\n",
    "    #     classification=True,\n",
    "    #     num_classes=1\n",
    "    # )\n",
    "    model = SEResNext50(in_channels=1, num_classes=1, spatial_dims=3)\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T16:39:38.62031Z",
     "iopub.status.busy": "2021-09-09T16:39:38.619784Z",
     "iopub.status.idle": "2021-09-09T16:39:38.647541Z",
     "shell.execute_reply": "2021-09-09T16:39:38.646658Z",
     "shell.execute_reply.started": "2021-09-09T16:39:38.620272Z"
    },
    "papermill": {
     "duration": 0.637077,
     "end_time": "2021-07-14T20:27:58.09407",
     "exception": false,
     "start_time": "2021-07-14T20:27:57.456993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "        self, \n",
    "        model, \n",
    "        device, \n",
    "        optimizer, \n",
    "        criterion\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.optimizer = optimizer\n",
    "        self.lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer=optimizer,\n",
    "            max_lr=LR,\n",
    "            epochs=EPOCHS,\n",
    "            div_factor=25,\n",
    "            pct_start=0.25,\n",
    "            steps_per_epoch=1,\n",
    "            final_div_factor=1e5\n",
    "        )\n",
    "        # self.lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=LR_DECAY)\n",
    "        self.criterion = criterion\n",
    "\n",
    "        self.best_valid_score = .0\n",
    "        self.n_patience = 0\n",
    "        self.lastmodel = None\n",
    "        \n",
    "        self.val_losses = []\n",
    "        self.train_losses = []\n",
    "        self.val_auc = []\n",
    "        \n",
    "    def fit(self, epochs, train_loader, valid_loader, save_path, patience):      \n",
    "        for n_epoch in range(1, epochs + 1):\n",
    "            self.info_message(\"EPOCH: {}\", n_epoch)\n",
    "            \n",
    "            train_loss, train_time = self.train_epoch(train_loader)\n",
    "            valid_loss, valid_auc, valid_time = self.valid_epoch(valid_loader)\n",
    "            \n",
    "            self.train_losses.append(train_loss)\n",
    "            self.val_losses.append(valid_loss)\n",
    "            self.val_auc.append(valid_auc)\n",
    "            \n",
    "            self.info_message(\n",
    "                \"[Epoch Train: {}] loss: {:.4f}, time: {:.2f} s\",\n",
    "                n_epoch, train_loss, train_time\n",
    "            )\n",
    "            \n",
    "            self.info_message(\n",
    "                \"[Epoch Valid: {}] loss: {:.4f}, auc: {:.4f}, time: {:.2f} s\",\n",
    "                n_epoch, valid_loss, valid_auc, valid_time\n",
    "            )\n",
    "\n",
    "            if self.best_valid_score < valid_auc: \n",
    "                self.save_model(n_epoch, save_path, valid_loss, valid_auc)\n",
    "                self.info_message(\n",
    "                     \"auc improved from {:.4f} to {:.4f}. Saved model to '{}'\", \n",
    "                    self.best_valid_score, valid_auc, self.lastmodel\n",
    "                )\n",
    "                self.best_valid_score = valid_auc\n",
    "                self.n_patience = 0\n",
    "            else:\n",
    "                self.n_patience += 1\n",
    "            \n",
    "            if self.n_patience >= patience:\n",
    "                self.info_message(\"\\nValid auc didn't improve last {} epochs.\", patience)\n",
    "                break\n",
    "            \n",
    "    def train_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "        t = time.time()\n",
    "        sum_loss = 0\n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            print(f\"Learning Rate: {param_group['lr']}\")\n",
    "\n",
    "        for step, batch in enumerate(train_loader, 1):\n",
    "            X = batch[\"X\"].clone().detach().float().to(self.device)\n",
    "            targets = batch[\"y\"].to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(X).squeeze(1)\n",
    "            # outputs = self.model(X)[0].squeeze(1)\n",
    "            loss = self.criterion(outputs, targets)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            sum_loss += loss.detach().item()\n",
    "            \n",
    "            self.optimizer.step()\n",
    "            \n",
    "            message = 'Train Step {}/{}, train_loss: {:.4f}'\n",
    "            self.info_message(message, step, len(train_loader), sum_loss/step, end=\"\\r\")\n",
    "            \n",
    "        self.lr_scheduler.step()\n",
    "        \n",
    "        return sum_loss/len(train_loader), int(time.time() - t)\n",
    "    \n",
    "    def valid_epoch(self, valid_loader):\n",
    "        self.model.eval()\n",
    "        t = time.time()\n",
    "        sum_loss = 0\n",
    "        y_all = []\n",
    "        outputs_all = []\n",
    "\n",
    "        for step, batch in enumerate(valid_loader, 1):\n",
    "            with torch.no_grad():\n",
    "                targets = batch[\"y\"].to(self.device)\n",
    "\n",
    "                # outputs = torch.sigmoid(self.model(batch[\"X\"].clone().detach().float().to(self.device)).squeeze(1))\n",
    "                outputs = self.model(batch[\"X\"].clone().detach().float().to(self.device))\n",
    "                outputs = outputs.squeeze(1)\n",
    "                outputs = torch.sigmoid(outputs)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "                sum_loss += loss.detach().item()\n",
    "\n",
    "                y_all.extend(batch[\"y\"].tolist())\n",
    "                outputs_all.extend(outputs.tolist())\n",
    "\n",
    "            message = 'Valid Step {}/{}, valid_loss: {:.4f}'\n",
    "            self.info_message(message, step, len(valid_loader), sum_loss/step, end=\"\\r\")\n",
    "            \n",
    "        auc = roc_auc_score(y_all, outputs_all)\n",
    "        \n",
    "        return sum_loss/len(valid_loader), auc, int(time.time() - t)\n",
    "    \n",
    "    def save_model(self, n_epoch, save_path, loss, auc):\n",
    "        self.lastmodel = f\"{save_path}-e{n_epoch}-loss{loss:.3f}-auc{auc:.3f}.pth\"\n",
    "        torch.save(\n",
    "            {\n",
    "                \"model_state_dict\": self.model.state_dict(),\n",
    "                \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "                \"best_valid_score\": self.best_valid_score,\n",
    "                \"n_epoch\": n_epoch,\n",
    "            },\n",
    "            self.lastmodel,\n",
    "        )\n",
    "        \n",
    "    def display_plots(self, mri_type):\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.title(\"{}: Training and Validation Loss\")\n",
    "        plt.plot(self.val_losses,label=\"val\")\n",
    "        plt.plot(self.train_losses,label=\"train\")\n",
    "        plt.xlabel(\"iterations\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.title(\"{}: Validation AUC-ROC\")\n",
    "        plt.plot(self.val_auc,label=\"val\")\n",
    "        plt.xlabel(\"iterations\")\n",
    "        plt.ylabel(\"AUC\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    \n",
    "    @staticmethod\n",
    "    def info_message(message, *args, end=\"\\n\"):\n",
    "        print(message.format(*args), end=end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T16:58:00.520823Z",
     "iopub.status.busy": "2021-09-09T16:58:00.520451Z",
     "iopub.status.idle": "2021-09-09T16:58:00.531215Z",
     "shell.execute_reply": "2021-09-09T16:58:00.530072Z",
     "shell.execute_reply.started": "2021-09-09T16:58:00.520782Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(model, df, mri_type, split):\n",
    "    print(\"Predict:\", mri_type, df.shape)\n",
    "    df.loc[:,\"MRI_Type\"] = mri_type\n",
    "    \n",
    "    landmarks = torch.load(os.path.join(landmarks_directory, (f\"{mri_type}_landmarks.npy\")))\n",
    "    landmarks_dict = {\n",
    "        \"default_image_name\": landmarks,\n",
    "    }\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    random_patches = 50\n",
    "    \n",
    "    preds = []\n",
    "    for _ in range(random_patches):\n",
    "        data_retriever = Dataset(\n",
    "            paths=df[\"BraTS21ID\"].values,\n",
    "            mri_type=df[\"MRI_Type\"].values,\n",
    "            split=split,\n",
    "            landmarks_dict=landmarks_dict\n",
    "        )\n",
    "\n",
    "        data_loader = torch_data.DataLoader(\n",
    "            data_retriever,\n",
    "            batch_size=8,\n",
    "            shuffle=False,\n",
    "            num_workers=8,\n",
    "        )\n",
    "        y_pred = []\n",
    "        ids = []\n",
    "        for e, batch in enumerate(data_loader, 1):\n",
    "            print(f\"{e + _ * 10}/{len(data_loader) * random_patches}\", end=\"\\r\")\n",
    "            with torch.no_grad():\n",
    "                tmp_pred = torch.sigmoid(model(batch[\"X\"].clone().detach().float().to(device)).squeeze(1)).cpu().numpy().squeeze()\n",
    "                if tmp_pred.size == 1:\n",
    "                    y_pred.append(tmp_pred)\n",
    "                else:\n",
    "                    y_pred.extend(tmp_pred.tolist())\n",
    "                ids.extend(batch[\"id\"].numpy().tolist())\n",
    "                \n",
    "        preds.append(y_pred)\n",
    "\n",
    "    preds = np.array(preds)\n",
    "    preds = preds.mean(0)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T16:39:38.649382Z",
     "iopub.status.busy": "2021-09-09T16:39:38.648964Z",
     "iopub.status.idle": "2021-09-09T16:58:00.518805Z",
     "shell.execute_reply": "2021-09-09T16:58:00.517962Z",
     "shell.execute_reply.started": "2021-09-09T16:39:38.649343Z"
    },
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 447.387602,
     "end_time": "2021-07-14T20:35:26.110421",
     "exception": false,
     "start_time": "2021-07-14T20:27:58.722819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def predict_mri_type(df, df_test, mri_type, skf):\n",
    "    oof_train = np.zeros((len(df)))\n",
    "    oof_test = np.zeros((len(df_test)))\n",
    "    oof_test_skf = np.empty((5, len(df_test)))\n",
    "\n",
    "    for i, (train_index, val_index) in enumerate(skf.split(df, df[\"MGMT_value\"], df[\"MGMT_value\"])):\n",
    "        df_train = df.iloc[train_index]\n",
    "        df_valid = df.iloc[val_index]\n",
    "        \n",
    "        train = df_train.copy()\n",
    "        valid = df_valid.copy()\n",
    "        train.loc[:,\"MRI_Type\"] = mri_type\n",
    "        valid.loc[:,\"MRI_Type\"] = mri_type\n",
    "\n",
    "        print(train.shape, valid.shape)\n",
    "        display(valid.head())\n",
    "        print(len(train))\n",
    "        display(valid.head())\n",
    "        print(len(valid))\n",
    "\n",
    "        landmarks = torch.load(os.path.join(landmarks_directory, (f\"{mri_type}_landmarks.npy\")))\n",
    "        landmarks_dict = {\n",
    "            \"default_image_name\": landmarks,\n",
    "        }\n",
    "\n",
    "        train_data_retriever = Dataset(\n",
    "            train[\"BraTS21ID\"].values, \n",
    "            train[\"MGMT_value\"].values, \n",
    "            train[\"MRI_Type\"].values,\n",
    "            landmarks_dict=landmarks_dict\n",
    "        )\n",
    "\n",
    "        valid_data_retriever = Dataset(\n",
    "            valid[\"BraTS21ID\"].values, \n",
    "            valid[\"MGMT_value\"].values,\n",
    "            valid[\"MRI_Type\"].values,\n",
    "            landmarks_dict=landmarks_dict\n",
    "        )\n",
    "\n",
    "        train_loader = torch_data.DataLoader(\n",
    "            train_data_retriever,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            num_workers=8,\n",
    "        )\n",
    "\n",
    "        valid_loader = torch_data.DataLoader(\n",
    "            valid_data_retriever, \n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            num_workers=8,\n",
    "        )\n",
    "\n",
    "        model = build_model()\n",
    "        model.to(device)\n",
    "\n",
    "        load_path = glob.glob(f\"{experiment_folder}/{model_paths}/fold_{i}/{mri_type}*\")[-1]\n",
    "        print(load_path)\n",
    "        model.load_state_dict(torch.load(load_path)[\"model_state_dict\"])\n",
    "\n",
    "        oof_train[val_index] = predict(model, df_valid, mri_type, \"train\")\n",
    "        oof_test_skf[i, :] = predict(model, df_test, mri_type, \"test\")\n",
    "\n",
    "    oof_test = oof_test_skf.mean(axis=0)\n",
    "\n",
    "    return oof_train, oof_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(f\"{data_directory}/sample_submission.csv\")\n",
    "df_test[\"MGMT_value\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rkf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(465, 3) (117, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BraTS21ID</th>\n",
       "      <th>MGMT_value</th>\n",
       "      <th>MRI_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>FLAIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>FLAIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>FLAIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>FLAIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>FLAIR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    BraTS21ID  MGMT_value MRI_Type\n",
       "5           8           1    FLAIR\n",
       "6           9           0    FLAIR\n",
       "7          11           1    FLAIR\n",
       "17         25           1    FLAIR\n",
       "18         26           1    FLAIR"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BraTS21ID</th>\n",
       "      <th>MGMT_value</th>\n",
       "      <th>MRI_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>FLAIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>FLAIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>FLAIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>FLAIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>FLAIR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    BraTS21ID  MGMT_value MRI_Type\n",
       "5           8           1    FLAIR\n",
       "6           9           0    FLAIR\n",
       "7          11           1    FLAIR\n",
       "17         25           1    FLAIR\n",
       "18         26           1    FLAIR"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2235535/1928236113.py\u001b[0m in \u001b[0;36mpredict_mri_type\u001b[0;34m(df, df_test, mri_type, skf)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mload_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{experiment_folder}/{model_paths}/fold_{i}/{mri_type}*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_state_dict\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "oof_train = []\n",
    "oof_test = []\n",
    "\n",
    "for mri_type in mri_types:\n",
    "    trn, tst = predict_mri_type(df, df_test, mri_type, rkf)\n",
    "    oof_train.append(trn)\n",
    "    oof_test.append(tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(f\"{experiment_folder}/oof_train.npy\", oof_train)\n",
    "# np.save(f\"{experiment_folder}/oof_test.npy\", oof_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_train = np.load(f\"{experiment_folder}/oof_train.npy\")\n",
    "# oof_test = np.load(f\"{experiment_folder}/oof_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis2: axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2235535/814430352.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moof_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moof_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mswapaxes\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/pytorch/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mswapaxes\u001b[0;34m(a, axis1, axis2)\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m     \"\"\"\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'swapaxes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/pytorch/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis2: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "x_train = np.swapaxes(np.array(oof_train), 0, 1)\n",
    "x_test = np.swapaxes(np.array(oof_test), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df), len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(f\"{data_directory}/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## meta learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, mri_type in enumerate(mri_types):\n",
    "    df[f\"level0_{mri_type}_preds\"] = x_train[:, i]\n",
    "    df_test[f\"level0_{mri_type}_preds\"] = x_test[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"MGMT_value\"].values\n",
    "X = df.drop([\"MGMT_value\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"BraTS21ID\" in X.columns:\n",
    "    X = X.drop([\"BraTS21ID\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'learning_rate': [0.005, 0.002, 0.0001],\n",
    "    'n_estimators': [1000, 2000, 5000],\n",
    "    'min_child_weight': [1, 10, 20],\n",
    "    'gamma': [1, 2, 5],\n",
    "    'subsample': [0.9, 1.0], # 0.6, 0.8, \n",
    "    'colsample_bytree': [0.9, 1.0],\n",
    "    'max_depth': [2, 3, 4, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = xgb.XGBClassifier(\n",
    "    # objective='binary:logistic',\n",
    "    # use_label_encoder=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_sklearn = make_scorer(roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_comb = 100\n",
    "\n",
    "skf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=52)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    gbc,\n",
    "    param_distributions=params,\n",
    "    n_iter=param_comb,\n",
    "    scoring=roc_auc_sklearn,\n",
    "    n_jobs=8,\n",
    "    cv=skf.split(X, y),\n",
    "    random_state=21,\n",
    ")\n",
    "\n",
    "random_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n All results:')\n",
    "print(random_search.cv_results_)\n",
    "print('\\n Best estimator:')\n",
    "print(random_search.best_estimator_)\n",
    "print('\\n Best normalized gini score for %d-fold search with %d parameter combinations:' % (NUM_FOLDS, param_comb))\n",
    "print(random_search.best_score_ * 2 - 1)\n",
    "print('\\n Best hyperparameters:')\n",
    "print(random_search.best_params_)\n",
    "results = pd.DataFrame(random_search.cv_results_)\n",
    "results.to_csv(f'{experiment_folder}/xgb-random-grid-search-results-01.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results[results[\"rank_test_score\"] < 8].sort_values(\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df_test.copy()\n",
    "\n",
    "if \"BraTS21ID\" in x_test.columns:\n",
    "    x_test = x_test.drop([\"BraTS21ID\"], axis=1)\n",
    "if \"MGMT_value\" in x_test.columns:\n",
    "    x_test = x_test.drop([\"MGMT_value\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_preds = random_search.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = test_preds[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T17:04:47.358254Z",
     "iopub.status.busy": "2021-09-09T17:04:47.357907Z",
     "iopub.status.idle": "2021-09-09T17:05:19.089039Z",
     "shell.execute_reply": "2021-09-09T17:05:19.086785Z",
     "shell.execute_reply.started": "2021-09-09T17:04:47.358222Z"
    }
   },
   "outputs": [],
   "source": [
    "# auc = roc_auc_score(y_valid, val_preds)\n",
    "# print(f\"Validation ensemble AUC: {auc:.4f}\")\n",
    "sns.displot(test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-09-09T16:58:32.413937Z",
     "iopub.status.idle": "2021-09-09T16:58:32.414306Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv(f\"{data_directory}/sample_submission.csv\")\n",
    "submission[\"MGMT_value\"] = test_preds\n",
    "submission.to_csv(f\"{experiment_folder}/submission_stacking.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_pred = np.array(oof_test).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(f\"{data_directory}/sample_submission.csv\")\n",
    "submission[\"MGMT_value\"] = tmp_pred\n",
    "submission.to_csv(f\"{experiment_folder}/submission_mean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
