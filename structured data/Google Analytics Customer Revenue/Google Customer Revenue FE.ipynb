{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "\n",
    "\n",
    "from plotly import tools\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "  \n",
    "from sklearn import model_selection, preprocessing, metrics\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, log_loss\n",
    "from sklearn.model_selection import KFold, GroupKFold, StratifiedKFold\n",
    "from sklearn.preprocessing import Imputer \n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from fastai.imports import *\n",
    "from fastai.torch_imports import *\n",
    "from fastai.transforms import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.sgdr import *\n",
    "from fastai.plots import *\n",
    "from fastai.structured import *\n",
    "from fastai.column_data import *\n",
    "PATH = 'data/'\n",
    "\n",
    "import torch\n",
    "import gc\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/extracted_fields_train.gz', dtype={'date': str, 'fullVisitorId': str, 'sessionId':str}, nrows=None)\n",
    "test = pd.read_csv('data/extracted_fields_test.gz', dtype={'date': str, 'fullVisitorId': str, 'sessionId':str}, nrows=None)\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folds(df=None, n_splits=5):\n",
    "    \"\"\"Returns dataframe indices corresponding to Visitors Group KFold\"\"\"\n",
    "    # Get sorted unique visitors\n",
    "    unique_vis = np.array(sorted(df['fullVisitorId'].unique()))\n",
    "\n",
    "    # Get folds\n",
    "    folds = GroupKFold(n_splits=n_splits)\n",
    "    fold_ids = []\n",
    "    ids = np.arange(df.shape[0])\n",
    "    for trn_vis, val_vis in folds.split(X=unique_vis, y=unique_vis, groups=unique_vis):\n",
    "        fold_ids.append(\n",
    "            [\n",
    "                ids[df['fullVisitorId'].isin(unique_vis[trn_vis])],\n",
    "                ids[df['fullVisitorId'].isin(unique_vis[val_vis])]\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    return fold_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6be7ebd7776a156b7db885fa7697ca0dd4e5c68f"
   },
   "source": [
    "# Functions (Feature engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train, test]:\n",
    "    df['vis_date'] = pd.to_datetime(df['visitStartTime'], unit='s')\n",
    "    df['sess_date_dow'] = df['vis_date'].dt.dayofweek\n",
    "    df['sess_date_hours'] = df['vis_date'].dt.hour\n",
    "    df['sess_date_dom'] = df['vis_date'].dt.day\n",
    "    df.sort_values(['fullVisitorId', 'vis_date'], ascending=True, inplace=True)\n",
    "    df['next_session_1'] = (\n",
    "        df['vis_date'] - df[['fullVisitorId', 'vis_date']].groupby('fullVisitorId')['vis_date'].shift(1)\n",
    "    ).astype(np.int64) // 1e9 // 60 // 60\n",
    "    df['next_session_2'] = (\n",
    "        df['vis_date'] - df[['fullVisitorId', 'vis_date']].groupby('fullVisitorId')['vis_date'].shift(-1)\n",
    "    ).astype(np.int64) // 1e9 // 60 // 60\n",
    "    \n",
    "#     df['max_visits'] = df['fullVisitorId'].map(\n",
    "#         df[['fullVisitorId', 'visitNumber']].groupby('fullVisitorId')['visitNumber'].max()\n",
    "#     )\n",
    "    \n",
    "    df['nb_pageviews'] = df['date'].map(\n",
    "        df[['date', 'totals.pageviews']].groupby('date')['totals.pageviews'].sum()\n",
    "    )\n",
    "    \n",
    "    df['ratio_pageviews'] = df['totals.pageviews'] / df['nb_pageviews']\n",
    "    \n",
    "#     df['nb_sessions'] = df['date'].map(\n",
    "#         df[['date']].groupby('date').size()\n",
    "#     )\n",
    "    \n",
    "#     df['nb_sessions_28_ma'] = df['date'].map(\n",
    "#         df[['date']].groupby('date').size().rolling(28, min_periods=7).mean()\n",
    "#     )\n",
    "\n",
    "#     df['nb_sessions_28_ma'] = df['nb_sessions'] / df['nb_sessions_28_ma']\n",
    "\n",
    "#     df['nb_sessions_per_day'] = df['date'].map(\n",
    "#         df[['date']].groupby('date').size()\n",
    "#     )\n",
    "    \n",
    "#     df['nb_visitors_per_day'] = df['date'].map(\n",
    "#         df[['date','fullVisitorId']].groupby('date')['fullVisitorId'].nunique()\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e07ce3724c9c6bb66f4839204f54f59c5826bf53"
   },
   "source": [
    "# Prepare data for deep-learning regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_features = [\n",
    "    'fullVisitorId', 'sessionId', 'totals_transactionRevenue', \n",
    "    'visitId', 'visitStartTime', 'date','vis_date', 'nb_sessions', 'max_visits'\n",
    "    #excluded after feature importance:\n",
    "]\n",
    "\n",
    "cat_cols = [\n",
    "    _f for _f in train.columns\n",
    "    if (_f not in excluded_features) & (train[_f].dtype == 'object' or train[_f].dtype == 'int64')\n",
    "]\n",
    "\n",
    "num_cols = [c for c in train.columns if c not in cat_cols and c not in excluded_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dep = 'totals.transactionRevenue'\n",
    "test[dep] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "00b3c090da16bd8c60d33186345486bcef9244c3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "print(\"prepare model ...\")\n",
    "X = train[cat_cols + num_cols + ['fullVisitorId']].copy()\n",
    "X_test = test[cat_cols + num_cols + ['fullVisitorId']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for v in cat_cols:\n",
    "    print(v)\n",
    "    X[v] = X[v].astype('category').cat.as_ordered()\n",
    "    \n",
    "\n",
    "X['fullVisitorId'] = X['fullVisitorId'].astype('category').cat.as_ordered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X.columns), len(X_test.columns), set(X_test.columns).difference(set(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x in X:\n",
    "    print(x)\n",
    "    print(X[x].dtype.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "apply_cats(X_test, X)\n",
    "#if this does not work it is probably because of a duplicated column name ( throws dataframe has no attribute dtype error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for v in num_cols:\n",
    "    X[v] = X[v].astype('float32')\n",
    "    X_test[v] = X_test[v].astype('float32')\n",
    "    \n",
    "\n",
    "X[dep] = X[dep].astype('float32')\n",
    "X[dep] = X[dep].fillna(0)\n",
    "X_test[dep] = X_test[dep].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_indexed = X.set_index(\"fullVisitorId\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataframes for deep-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df, y, nas, mapper = proc_df(X_indexed, 'totals.transactionRevenue', do_scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test_indexed = X_test.set_index(\"fullVisitorId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test, _, nas, mapper = proc_df(X_test_indexed, 'totals.transactionRevenue', do_scale=True,\n",
    "                                  mapper=mapper, na_dict=nas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = len(df)\n",
    "samp_size = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_size = len(train[train.date < '2017-06-01'])\n",
    "#val_idx = list(range(train_size, len(df))); len(val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(40)\n",
    "random.seed(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.15\n",
    "val_idx = get_cv_idxs(n, val_pct=train_ratio) #list(range(train_size, len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_idx)/len(df) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yl = np.log1p(y)\n",
    "\n",
    "max_y = np.max(yl)\n",
    "\n",
    "y_range = (0, max_y*1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "md = ColumnarModelData.from_data_frame(PATH, val_idx, df, yl, cat_flds=cat_cols, bs=512, test_df=df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_sz = [(c, len(X[c].cat.categories)+1) for c in cat_cols]\n",
    "cat_sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_szs = [(c, max(10, min(50, (c+1)//2))) for _,c in cat_sz]\n",
    "emb_szs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = md.get_learner(emb_szs, len(df.columns)-len(cat_cols),\n",
    "                   0.04, 1, [1000,500], [0.001, 0.01], y_range=y_range)\n",
    "\n",
    "#m = md.get_learner(emb_szs, len(df.columns)-len(cat_cols), 0.04, 1, \n",
    "#                           [  2000,  3000, 2500, 2250, 2000, 1500, 1000, 500], \n",
    "#                           [0.0001,0.0002,0.0005,0.0007,0.001,0.002,0.008,0.004], y_range=y_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.lr_find(end_lr=1e-2)\n",
    "m.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 10 ** -4.7\n",
    "lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def exp_rmse(y_pred, targ):\n",
    "    return math.sqrt(mean_squared_error(targ, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(lr, 3, cycle_len = 1, metrics=[exp_rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save(\"customer_revenue_visitor_3e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m.load(\"customer_revenue_visitor_3e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(lr, 3, cycle_len = 1, cycle_mult = 1, metrics=[exp_rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save(\"customer_revenue_visitor_6e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.load(\"customer_revenue_visitor_6e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(lr, 3, cycle_len = 1, cycle_mult = 1, metrics=[exp_rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save(\"customer_revenue_visitor_9e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.load(\"customer_revenue_visitor_9e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m.fit(lr, 1, cycle_len = 3, cycle_mult = 1, metrics=[exp_rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save(\"customer_revenue_visitor_9e_3eh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.load(\"customer_revenue_visitor_9e_3eh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(lr, 1, cycle_len = 1, cycle_mult = 1, metrics=[exp_rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save(\"customer_revenue_visitor_10e_3eh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.load(\"customer_revenue_visitor_10e_3eh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(lr, 1, cycle_len = 3, cycle_mult = 1, metrics=[exp_rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save(\"customer_revenue_visitor_10e_6eh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.load(\"customer_revenue_visitor_10e_6eh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(lr, 1, cycle_len = 2, cycle_mult = 1, metrics=[exp_rmse])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FullvisitorId indexed visitor level cv 15% train/validation split) using better features:\n",
    "\n",
    "### 3e\n",
    "\n",
    "- 2.908336154736353, 1.6928364618530287\n",
    "\n",
    "### 6e\n",
    "\n",
    "- 2.6615966842603833, 1.6192395528417023\n",
    "\n",
    "### 9e\n",
    "\n",
    "- 2.6171998919897654, 1.6051034699929898\n",
    "\n",
    "### 9e3eh \n",
    "\n",
    "- 2.604989178404238, 1.601011082221721\n",
    "\n",
    "### 10e3eh \n",
    "\n",
    "- 2.6047352634459537, 1.6008542096483447\n",
    "\n",
    "## Date indexed visitor level cv (15.32% train/validation split) using better features:\n",
    "\n",
    "### 3e\n",
    "\n",
    "- 2.8000360318887103, 1.6550484801023893\n",
    "\n",
    "### 5e\n",
    "\n",
    "- 2.640869347781692, 1.6067949968854136\n",
    "\n",
    "\n",
    "## Date indexed visitor level cv (15.32% train/validation split):\n",
    "\n",
    "### 3e\n",
    "\n",
    "- 3.0265201163562265, RMSE 1.3110982701455685 \n",
    "\n",
    "### 6e\n",
    "\n",
    "- 2.8375099688976335, RMSE 1.2135674675795136 \n",
    "\n",
    "### 6e9em\n",
    "\n",
    "- 2.796606798042731, RMSE 1.1948834400361132\n",
    "\n",
    "### 9e9em \n",
    "\n",
    "- 2.7970978266890083, RMSE 1.1941790717723948"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fi = nn_feat_importance(m, md, cat_cols, num_cols)\n",
    "fi.plot('cols', 'imp', 'barh', figsize=(12,20), legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create user level predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds_train = m.predict_dl(m.data.trn_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds_val = m.predict_dl(m.data.val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds = m.predict(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds.mean(), np.concatenate([log_preds_train, log_preds_val]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yl.mean(), log_preds_train.mean(), log_preds_val.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds_train = np.concatenate([log_preds_train, log_preds_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['predictions'] = log_preds_train\n",
    "test['predictions'] = log_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user = train[cat_cols + num_cols + ['fullVisitorId', 'predictions']]\n",
    "test_user = test[cat_cols + num_cols + ['fullVisitorId', 'predictions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in cat_cols:\n",
    "    train_user[f], indexer = pd.factorize(train_user[f])\n",
    "    test_user[f] = indexer.get_indexer(test_user[f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_data = train_user[cat_cols + num_cols + ['fullVisitorId']].groupby('fullVisitorId').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create a list of predictions for each Visitor\n",
    "trn_pred_list = train_user[['fullVisitorId', 'predictions']].groupby('fullVisitorId')\\\n",
    "    .apply(lambda df: list(df.predictions))\\\n",
    "    .apply(lambda x: {'pred_'+str(i): pred for i, pred in enumerate(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_all_predictions = pd.DataFrame(list(trn_pred_list.values), index=trn_data.index)\n",
    "trn_feats = trn_all_predictions.columns\n",
    "trn_all_predictions['t_mean'] = np.log1p(trn_all_predictions[trn_feats].mean(axis=1))\n",
    "trn_all_predictions['t_median'] = np.log1p(trn_all_predictions[trn_feats].median(axis=1))\n",
    "trn_all_predictions['t_sum_log'] = np.log1p(trn_all_predictions[trn_feats]).sum(axis=1)\n",
    "trn_all_predictions['t_sum_act'] = np.log1p(trn_all_predictions[trn_feats].fillna(0).sum(axis=1))\n",
    "trn_all_predictions['t_nb_sess'] = trn_all_predictions[trn_feats].isnull().sum(axis=1)\n",
    "full_data = pd.concat([trn_data, trn_all_predictions], axis=1)\n",
    "del trn_data, trn_all_predictions\n",
    "gc.collect()\n",
    "full_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sub_pred_list = test_user[['fullVisitorId', 'predictions']].groupby('fullVisitorId')\\\n",
    "    .apply(lambda df: list(df.predictions))\\\n",
    "    .apply(lambda x: {'pred_'+str(i): pred for i, pred in enumerate(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data = test_user[cat_cols + num_cols + ['fullVisitorId']].groupby('fullVisitorId').mean()\n",
    "sub_all_predictions = pd.DataFrame(list(sub_pred_list.values), index=sub_data.index)\n",
    "for f in trn_feats:\n",
    "    if f not in sub_all_predictions.columns:\n",
    "        sub_all_predictions[f] = np.nan\n",
    "sub_all_predictions['t_mean'] = np.log1p(sub_all_predictions[trn_feats].mean(axis=1))\n",
    "sub_all_predictions['t_median'] = np.log1p(sub_all_predictions[trn_feats].median(axis=1))\n",
    "sub_all_predictions['t_sum_log'] = np.log1p(sub_all_predictions[trn_feats]).sum(axis=1)\n",
    "sub_all_predictions['t_sum_act'] = np.log1p(sub_all_predictions[trn_feats].fillna(0).sum(axis=1))\n",
    "sub_all_predictions['t_nb_sess'] = sub_all_predictions[trn_feats].isnull().sum(axis=1)\n",
    "sub_full_data = pd.concat([sub_data, sub_all_predictions], axis=1)\n",
    "del sub_data, sub_all_predictions\n",
    "gc.collect()\n",
    "sub_full_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user['target'] = yl\n",
    "trn_user_target = train_user[['fullVisitorId', 'target']].groupby('fullVisitorId').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in full_data.columns:\n",
    "    print(f +  \" - \" + str(full_data[f].dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in cat_cols:\n",
    "    print(v)\n",
    "    full_data[v] = full_data[v].astype('category').cat.as_ordered()\n",
    "    \n",
    "    \n",
    "full_data['t_nb_sess'] = full_data['t_nb_sess'].astype('category').cat.as_ordered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "apply_cats(sub_full_data, full_data)\n",
    "#if this does not work it is probably because of a duplicated column name ( throws dataframe has no attribute dtype error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataframes for deep-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['totals.transactionRevenue'] = trn_user_target['target']\n",
    "sub_full_data['totals.transactionRevenue'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.shape, sub_full_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = full_data.apply(lambda x: pd.to_numeric(x, downcast='float') if x.dtype == \"float64\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_full_data = sub_full_data.apply(lambda x: pd.to_numeric(x, downcast='float') if x.dtype == \"float64\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.reset_index().to_feather('Dataframes/full_data')\n",
    "sub_full_data.reset_index().to_feather('Dataframes/sub_full_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.read_feather('Dataframes/full_data')\n",
    "sub_full_data = pd.read_feather('Dataframes/sub_full_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''excluded_features = [\n",
    "    'fullVisitorId', 'sessionId', 'totals_transactionRevenue', \n",
    "    'visitId', 'visitStartTime', 'date'\n",
    "    #excluded after feature importance:\n",
    "]\n",
    "\n",
    "cat_cols = [\n",
    "    _f for _f in full_data.columns\n",
    "    if (_f not in excluded_features) & (full_data[_f].dtype.name == 'category')\n",
    "]\n",
    "\n",
    "num_cols = [c for c in full_data.columns if c not in cat_cols and c not in excluded_features]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df, y_user, nas, mapper = proc_df(full_data, 'totals.transactionRevenue', do_scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del full_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test, _, nas, mapper = proc_df(sub_full_data, 'totals.transactionRevenue', do_scale=True, \n",
    "                                  mapper=mapper, na_dict=nas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del sub_full_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = len(df)\n",
    "samp_size = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_size = len(df) - 110000  #percent user visitor level: 15.320371868405239\n",
    "#val_idx = list(range(train_size, len(df))); len(val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_idx)/len(df) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yl_user = np.log1p(y_user)\n",
    "\n",
    "max_y_user = np.max(yl_user)\n",
    "\n",
    "y_range_user = (0, max_y_user*1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "md = ColumnarModelData.from_data_frame(PATH, val_idx, df, yl_user, cat_flds=cat_cols, bs=512, test_df=df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat_sz = [(c, len(full_data[c].cat.categories)+1) for c in cat_cols]\n",
    "cat_sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emb_szs = [(c, max(10, min(50, (c+1)//2))) for _,c in cat_sz]\n",
    "emb_szs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = md.get_learner(emb_szs, len(df.columns)-len(cat_cols),\n",
    "                   0.04, 1, [1000,500], [0.001, 0.01], y_range=y_range_user)\n",
    "\n",
    "#m = md.get_learner(emb_szs, len(df.columns)-len(cat_cols), 0.04, 1, \n",
    "#                           [  2000,  3000, 2500, 2250, 2000, 1500, 1000, 500], \n",
    "#                           [0.0001,0.0002,0.0005,0.0007,0.001,0.002,0.008,0.004], y_range_user=y_range_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.lr_find(end_lr=1e-2)\n",
    "m.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 10 ** -4.6\n",
    "lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def exp_rmse(y_pred, targ):\n",
    "    return math.sqrt(mean_squared_error(targ, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(lr, 1, cycle_len = 3, metrics=[exp_rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save(\"customer_revenue_3e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m.load(\"customer_revenue_3e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(lr, 3, cycle_len = 2, cycle_mult = 2, metrics=[exp_rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save(\"customer_revenue_3e_14em\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m.load(\"customer_revenue_3e_14em\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(lr, 5, cycle_len = 1, cycle_mult = 1, metrics=[exp_rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save(\"customer_revenue_3e_45em\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.load(\"customer_revenue_3e_45em\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(lr, 4, cycle_len = 1, cycle_mult = 2, metrics=[exp_rmse])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=m.predict_with_targs()\n",
    "x = torch.from_numpy(x)\n",
    "y = torch.from_numpy(y)\n",
    "exp_rmse(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "log_preds = m.predict(True)\n",
    "\n",
    "log_preds, log_preds.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submission = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submission['PredictedLogRevenue'] = np.expm1(log_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['PredictedLogRevenue'][(np.log(submission['totals.pageviews']) / np.log(submission['totals.hits'])) < 0.4].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission['PredictedLogRevenue'][(submission['totals_pageviews'] / submission['totals_hits']) < 0.4] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submission_grouped = submission.groupby(['fullVisitorId'], as_index=False).agg({'PredictedLogRevenue':'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submission_grouped['PredictedLogRevenue'] = np.log1p(submission_grouped['PredictedLogRevenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_grouped['PredictedLogRevenue'].mean(), yl.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(submission_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csv_fn=f'{PATH}submission.csv'\n",
    "\n",
    "submission_grouped[['fullVisitorId','PredictedLogRevenue']].to_csv(csv_fn, index=False)\n",
    "\n",
    "submission_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(20,10))\n",
    "#plt.plot(X['date'], y)\n",
    "#plt.plot(submission['date'], submission['PredictedLogRevenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
